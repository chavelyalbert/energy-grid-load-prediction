{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff03a592-9ef9-4ef2-9f55-e070f981f3ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This notebook is used to fill NULLS values in the train set.\n",
    "# It creates a mask of known values and substitutes them with the mean, median and fbfill of that type of generation for the country. If all values per type are NULL the values will keep as NULL\n",
    "# Computes the MAE of the filled values and the known, and selectsselect per column the best filling method for each column (smallest MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "571b5540-5972-49fc-b277-6cbad38466b8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load dataset"
    }
   },
   "outputs": [],
   "source": [
    "all_data = spark.table(\"workspace.live_data.electricity_and_weather_europe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3196e46-e5db-49f7-9391-05e3e6917f13",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "There are columns that represent the same kind of generation but correspond to the old database"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'Hydro_Pumped_Storage',\n",
    "    'Hydro_Run_of_river_and_poundage',\n",
    "    'Hydro_Water_Reservoir',\n",
    "    'Nuclear',\n",
    "    'Solar',\n",
    "    'Wind_Onshore',\n",
    "    'Biomass',\n",
    "    'Fossil_Brown_coal_Lignite',\n",
    "    'Fossil_Coal_derived_gas',\n",
    "    'Fossil_Gas',\n",
    "    'Fossil_Hard_coal',\n",
    "    'Fossil_Oil',\n",
    "    'Waste',\n",
    "    'Wind_Offshore',\n",
    "    'Other',\n",
    "    'Other_renewable',\n",
    "    'Fossil_Peat',\n",
    "    'Energy_storage',\n",
    "    'Fossil_Oil_shale'\n",
    "]\n",
    "all_data = all_data.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b6c93b9-283b-4df1-97a1-b94dd511b30c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Remove all rows corresponding o countries that don't have information about generation"
    }
   },
   "outputs": [],
   "source": [
    "missing_countries = [\"DK\", \"FI\", \"LV\", \"SE\", \"EE\", \"GR\", \"RO\", \"SI\", \"NO\", \"CH\", \"BG\"]\n",
    "all_data = all_data.filter(~all_data[\"country\"].isin(missing_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "483a15ac-51cf-461d-b7e0-916cc06acf29",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select only columns that should be imputed (we know from EDA process)"
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    c for c, t in all_data.dtypes\n",
    "    if t in (\"double\", \"float\", \"int\", \"bigint\")\n",
    "    and (\n",
    "        c.endswith(\"__Actual_Aggregated\")\n",
    "        or c.endswith(\"__Actual_Consumption\")\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd311f60-a734-4525-9227-c485710f0581",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Remove columns that are fully empty"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Count nulls per column\n",
    "null_counts = all_data.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in numeric_cols]).collect()[0].asDict()\n",
    "\n",
    "# Identify columns where all values are null\n",
    "all_null_cols = [c for c, cnt in null_counts.items() if cnt == all_data.count()]\n",
    "\n",
    "# Drop these columns\n",
    "if all_null_cols:\n",
    "    all_data = all_data.drop(*all_null_cols)\n",
    "\n",
    "# Update numeric_cols list\n",
    "numeric_cols = [c for c in numeric_cols if c not in all_null_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebde148b-5e92-467a-8285-94f0cd7100cf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Best method to fill (determined in exploratory notebook)"
    }
   },
   "outputs": [],
   "source": [
    "best_method_map = {\n",
    "    \"Biomass__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Biomass__Actual_Consumption\": \"mean\",\n",
    "    \"Energy_storage__Actual_Aggregated\": \"median\",\n",
    "    \"Energy_storage__Actual_Consumption\": \"median\",\n",
    "    \"Fossil_Brown_coal_Lignite__Actual_Aggregated\": \"mean\",\n",
    "    \"Fossil_Coal_derived_gas__Actual_Aggregated\": \"mean\",\n",
    "    \"Fossil_Gas__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Fossil_Gas__Actual_Consumption\": \"mean\",\n",
    "    \"Fossil_Hard_coal__Actual_Aggregated\": \"mean\",\n",
    "    \"Fossil_Hard_coal__Actual_Consumption\": \"mean\",\n",
    "    \"Fossil_Oil__Actual_Aggregated\": \"mean\",\n",
    "    \"Fossil_Oil__Actual_Consumption\": \"mean\",\n",
    "    \"Fossil_Oil_shale__Actual_Aggregated\": \"mean\",\n",
    "    \"Fossil_Peat__Actual_Aggregated\": \"mean\",\n",
    "    \"Geothermal__Actual_Aggregated\": \"mean\",\n",
    "    \"Geothermal__Actual_Consumption\": \"mean\",\n",
    "    \"Hydro_Pumped_Storage__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Hydro_Pumped_Storage__Actual_Consumption\": \"ffill_bfill\",\n",
    "    \"Hydro_Run_of_river_and_poundage__Actual_Aggregated\": \"mean\",\n",
    "    \"Hydro_Run_of_river_and_poundage__Actual_Consumption\": \"mean\",\n",
    "    \"Hydro_Water_Reservoir__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Hydro_Water_Reservoir__Actual_Consumption\": \"mean\",\n",
    "    \"Marine__Actual_Aggregated\": \"mean\",\n",
    "    \"Nuclear__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Nuclear__Actual_Consumption\": \"ffill_bfill\",\n",
    "    \"Other__Actual_Aggregated\": \"mean\",\n",
    "    \"Other__Actual_Consumption\": \"mean\",\n",
    "    \"Other_renewable__Actual_Aggregated\": \"mean\",\n",
    "    \"Other_renewable__Actual_Consumption\": \"mean\",\n",
    "    \"Solar__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Solar__Actual_Consumption\": \"mean\",\n",
    "    \"Waste__Actual_Aggregated\": \"mean\",\n",
    "    \"Waste__Actual_Consumption\": \"mean\",\n",
    "    \"Wind_Offshore__Actual_Aggregated\": \"mean\",\n",
    "    \"Wind_Offshore__Actual_Consumption\": \"ffill_bfill\",\n",
    "    \"Wind_Onshore__Actual_Aggregated\": \"ffill_bfill\",\n",
    "    \"Wind_Onshore__Actual_Consumption\": \"mean\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "107a9909-94b1-4a7c-b54a-9751d24d4e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window# Window definitions for forward/backward fill\n",
    "\n",
    "w_ff = Window.partitionBy(\"country\").orderBy(\"index\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "w_bf = Window.partitionBy(\"country\").orderBy(F.col(\"index\").desc()).rowsBetween(Window.unboundedPreceding, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffbca593-6e82-4cbf-bc63-461b2d848fcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Impute columns efficiently by batching transformations\n",
    "mean_cols = [col for col, method in best_method_map.items() if method == \"mean\"]\n",
    "median_cols = [col for col, method in best_method_map.items() if method == \"median\"]\n",
    "ffill_bfill_cols = [col for col, method in best_method_map.items() if method == \"ffill_bfill\"]\n",
    "\n",
    "# Mean imputation\n",
    "if mean_cols:\n",
    "    mean_exprs = [F.mean(col).alias(f\"mean_{col}\") for col in mean_cols]\n",
    "    mean_df = all_data.groupBy(\"country\").agg(*mean_exprs)\n",
    "    all_data = all_data.join(mean_df, on=\"country\", how=\"left\")\n",
    "    for col in mean_cols:\n",
    "        all_data = all_data.withColumn(col, F.when(F.col(col).isNull(), F.col(f\"mean_{col}\")).otherwise(F.col(col)))\n",
    "        all_data = all_data.drop(f\"mean_{col}\")\n",
    "\n",
    "# Median imputation\n",
    "if median_cols:\n",
    "    median_exprs = [F.expr(f'percentile_approx({col}, 0.5)').alias(f\"median_{col}\") for col in median_cols]\n",
    "    median_df = all_data.groupBy(\"country\").agg(*median_exprs)\n",
    "    all_data = all_data.join(median_df, on=\"country\", how=\"left\")\n",
    "    for col in median_cols:\n",
    "        all_data = all_data.withColumn(col, F.when(F.col(col).isNull(), F.col(f\"median_{col}\")).otherwise(F.col(col)))\n",
    "        all_data = all_data.drop(f\"median_{col}\")\n",
    "\n",
    "# Forward/backward fill imputation\n",
    "for col in ffill_bfill_cols:\n",
    "    all_data = all_data.withColumn(f\"{col}_ffill\", F.last(F.col(col), ignorenulls=True).over(w_ff))\n",
    "    all_data = all_data.withColumn(f\"{col}_fbfill\", F.coalesce(F.col(f\"{col}_ffill\"), F.last(F.col(col), ignorenulls=True).over(w_bf)))\n",
    "    all_data = all_data.drop(col, f\"{col}_ffill\").withColumnRenamed(f\"{col}_fbfill\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5004bb3-bf53-4154-9b68-b837776560b1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fill with zero the remaining NULLS"
    }
   },
   "outputs": [],
   "source": [
    "# some countries don't provide information about certain kind of energy sources, so we can fill them with zeros, like nuclear energy\n",
    "\n",
    "all_data = all_data.fillna(0, subset=numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f5b2a1d-2a7a-429f-99c1-778840fb4080",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_name = \"live_data\"\n",
    "\n",
    "all_data.write \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"overwriteSchema\", \"true\") \\\n",
    "  .saveAsTable(f\"{schema_name}.electricity_and_weather_europe_imputed\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_filling_nans",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
