{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27c87e88-9604-426c-aa8c-79393a33bff8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "%pip install xgboost==2.0.3 lightgbm==4.1.0\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48f2f149-8b9f-4f96-9b7a-4c5693f6ebf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "data_df = spark.table(\"workspace.live_data.electricity_and_weather_europe_imputed\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5480764-c1f6-4811-8b3d-ad7d6c21069f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "\n",
    "def create_clean_features(df):\n",
    "    \"\"\"\n",
    "    Create features WITHOUT any data leakage.\n",
    "    Excludes: net_imports, stress_lag_*, reserve_margin_ml, forecast_load_error\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.sort_values(['country', 'index']).reset_index(drop=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEMPORAL FEATURES\n",
    "    # ========================================================================\n",
    "    \n",
    "    df['hour'] = df['index'].dt.hour\n",
    "    df['month'] = df['index'].dt.month\n",
    "    df['day_of_week'] = df['index'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # Peak hours\n",
    "    df['is_morning_peak'] = df['hour'].isin([7, 8, 9]).astype(int)\n",
    "    df['is_evening_peak'] = df['hour'].isin([18, 19, 20, 21]).astype(int)\n",
    "    df['is_peak_hour'] = (df['is_morning_peak'] | df['is_evening_peak']).astype(int)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LAG FEATURES (Using past values only - NO stress lags!)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Load lags\n",
    "    for lag in [1, 24]:\n",
    "        df[f'load_lag_{lag}h'] = df.groupby('country')['Actual_Load'].shift(lag)\n",
    "    \n",
    "    # Import lags (using past net_imports - legitimate!)\n",
    "    df['imports_lag_1h'] = df.groupby('country')['net_imports'].shift(1)\n",
    "    \n",
    "    # Temperature lags\n",
    "    df['temp_lag_1h'] = df.groupby('country')['mean_temperature_c'].shift(1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ROLLING STATISTICS\n",
    "    # ========================================================================\n",
    "    \n",
    "    df['load_rolling_mean_24h'] = df.groupby('country')['Actual_Load'].transform(\n",
    "        lambda x: x.rolling(window=24, min_periods=1).mean()\n",
    "    )\n",
    "    df['load_rolling_std_24h'] = df.groupby('country')['Actual_Load'].transform(\n",
    "        lambda x: x.rolling(window=24, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    df['imports_rolling_mean_24h'] = df.groupby('country')['net_imports'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=24, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Change features\n",
    "    df['load_change_1h'] = df.groupby('country')['Actual_Load'].diff(1)\n",
    "    df['load_change_24h'] = df.groupby('country')['Actual_Load'].diff(24)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INTERACTION FEATURES\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Load-forecast interactions\n",
    "    df['load_forecast_diff'] = df['Actual_Load'] - df['Forecasted_Load']\n",
    "    df['load_forecast_ratio'] = df['Actual_Load'] / (df['Forecasted_Load'] + 1e-6)\n",
    "    df['load_forecast_error_pct'] = np.abs(df['load_forecast_diff']) / (df['Forecasted_Load'] + 1e-6) * 100\n",
    "    \n",
    "    # Weather-load interactions\n",
    "    df['load_per_temp'] = df['Actual_Load'] / (df['mean_temperature_c'] + 20)\n",
    "    df['temp_load_product'] = df['mean_temperature_c'] * df['Actual_Load'] / 10000\n",
    "    \n",
    "    # Weather extremes\n",
    "    df['is_very_cold'] = (df['mean_temperature_c'] < 0).astype(int)\n",
    "    df['temp_extreme'] = df['is_very_cold'].astype(int)\n",
    "    \n",
    "    # Wind power potential\n",
    "    df['wind_power_index'] = df['mean_wind_speed'] ** 3 / 100\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SEASONALITY\n",
    "    \n",
    "    df['hourly_avg_load'] = df.groupby(['country', 'hour'])['Actual_Load'].transform('mean')\n",
    "    df['load_deviation_from_hourly_avg'] = df['Actual_Load'] - df['hourly_avg_load']\n",
    "    \n",
    "    df['daily_avg_load'] = df.groupby(['country', 'day_of_week'])['Actual_Load'].transform('mean')\n",
    "    df['load_deviation_from_daily_avg'] = df['Actual_Load'] - df['daily_avg_load']\n",
    "    \n",
    "    print(\"âœ“ Feature engineering complete\\n\")\n",
    "    return df\n",
    "\n",
    "# Apply to datasets\n",
    "data_df = create_clean_features(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b60ad27f-0559-4ad4-a51c-daf8b8159e57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DATA PREPARATION\")\n",
    "\n",
    "# ============================================================================\n",
    "# Select final features (keep best performers, remove redundant)\n",
    "# ============================================================================\n",
    "\n",
    "# Keep only essential features\n",
    "features_to_keep = [\n",
    "    # Load features\n",
    "    'Actual_Load', 'Forecasted_Load',\n",
    "    \n",
    "    # Load lags\n",
    "    'load_lag_1h', 'load_lag_24h',\n",
    "    \n",
    "    # Load derived\n",
    "    'load_rolling_mean_24h', 'load_rolling_std_24h',\n",
    "    'load_change_1h', 'load_change_24h',\n",
    "    'load_forecast_diff', 'load_forecast_ratio', 'load_forecast_error_pct',\n",
    "    'load_deviation_from_hourly_avg', 'load_deviation_from_daily_avg',\n",
    "    \n",
    "    # Weather features\n",
    "    'mean_temperature_c', 'mean_wind_speed', 'mean_ssrd',\n",
    "    'solar_forecast', 'wind_forecast',\n",
    "    'temp_lag_1h',\n",
    "    \n",
    "    # Weather derived\n",
    "    'load_per_temp', 'temp_load_product', 'is_very_cold', 'temp_extreme',\n",
    "    'wind_power_index',\n",
    "    \n",
    "    # Import features (past values only!)\n",
    "    'imports_lag_1h',\n",
    "    'imports_rolling_mean_24h',\n",
    "    \n",
    "    # Temporal features\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'month_sin', 'month_cos',\n",
    "    'day_of_week_sin', 'day_of_week_cos',\n",
    "    'is_weekend', 'is_morning_peak', 'is_evening_peak', 'is_peak_hour',\n",
    "    \n",
    "    # Country\n",
    "    'country'\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# Define clean feature set (exclude leakage and metadata)\n",
    "# ============================================================================\n",
    "\n",
    "LEAKAGE_COLS = [\n",
    "    # Metadata\n",
    "    'index', 'country',\n",
    "    # Target\n",
    "    'grid_stress_score',\n",
    "    # Data leakage - components of target\n",
    "    'reserve_margin_ml', 'forecast_load_error', 'load_rel_error',\n",
    "    'net_imports',  # Used to calculate T7/T8\n",
    "    'P10_net', 'P90_net',  # Thresholds\n",
    "    'score_reserve_margin', 'score_load_error', 'score_T7', 'score_T8',\n",
    "    'T7_high_exports', 'T8_high_imports',\n",
    "    # Redundant temporal\n",
    "    'hour', 'month', 'day_of_week'\n",
    "]\n",
    "\n",
    "# Get feature candidates\n",
    "all_cols = data_df.columns.tolist()\n",
    "feature_candidates = [col for col in all_cols if col not in LEAKAGE_COLS]\n",
    "\n",
    "# Add any generation features that aren't too sparse\n",
    "generation_features = [f for f in feature_candidates \n",
    "                      if 'Actual_Aggregated' in f \n",
    "                      and data_df[f].isnull().sum() / len(data_df) < 0.80]\n",
    "\n",
    "final_features = features_to_keep + generation_features\n",
    "\n",
    "# Remove any that don't exist\n",
    "final_features = [f for f in final_features if f in data_df.columns]\n",
    "\n",
    "# ============================================================================\n",
    "# Prepare dataset\n",
    "# ============================================================================\n",
    "\n",
    "data_with_features = data_df[final_features].copy()\n",
    "\n",
    "data_with_features = data_with_features.fillna(0)\n",
    "\n",
    "country_original = data_with_features['country'].copy()\n",
    "\n",
    "# One-hot encode country\n",
    "if 'country' in data_with_features.columns:\n",
    "    data_with_features = pd.get_dummies(data_with_features, columns=['country'], prefix='country', drop_first=False)\n",
    "\n",
    "data_with_features['country'] = country_original\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ecd12b-4508-4a29-a54e-7b364169c8a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "schema_name = \"live_data\"\n",
    "\n",
    "# Save data\n",
    "spark_df = spark.createDataFrame(data_with_features)\n",
    "spark_df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(f\"{schema_name}.electricity_and_weather_europe_imputed_with_features\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_features_definition",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
