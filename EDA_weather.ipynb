{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a00a98f8-a9fe-43d4-a2a3-ea8e4e91d96a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"INVESTIGATING WEATHER_HOURLY load_id COLUMN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define catalog paths\n",
    "CATALOG = \"curlybyte_solutions_rawdata_europe_grid_load\"\n",
    "WEATHER_SCHEMA = \"european_weather_raw\"\n",
    "\n",
    "# Load weather table\n",
    "weather = spark.table(f\"{CATALOG}.{WEATHER_SCHEMA}.weather_hourly\")\n",
    "\n",
    "print(\"\\nSample weather_hourly data with load_id:\")\n",
    "display(weather.select('timestamp', 'lat', 'lon', 'temperature_c', 'wind_speed', 'load_id').limit(10))\n",
    "\n",
    "print(\"\\nUnique load_id patterns:\")\n",
    "display(weather.select('load_id').distinct().limit(20))\n",
    "\n",
    "# Check if load_id contains country codes\n",
    "print(\"\\nChecking if load_id contains country information...\")\n",
    "sample_load_ids = weather.select('load_id').distinct().limit(100).toPandas()\n",
    "print(\"\\nFirst 20 unique load_ids:\")\n",
    "for i, load_id in enumerate(sample_load_ids['load_id'].head(20)):\n",
    "    print(f\"  {i+1}. {load_id}\")\n",
    "\n",
    "# Count total unique load_ids\n",
    "total_load_ids = weather.select('load_id').distinct().count()\n",
    "print(f\"\\nTotal unique load_ids: {total_load_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5177c980-7035-429e-951e-e33a4bfecfb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08bdbdbb-1ebc-4975-a2dd-a872655eeb9c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "print(\"ANALYZING WEATHER COORDINATES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get sample coordinates for each load_id\n",
    "print(\"\\nCoordinates by load_id:\")\n",
    "weather_coords = weather.groupBy('load_id').agg(\n",
    "    F.min('lat').alias('min_lat'),\n",
    "    F.max('lat').alias('max_lat'),\n",
    "    F.min('lon').alias('min_lon'),\n",
    "    F.max('lon').alias('max_lon'),\n",
    "    F.count('*').alias('row_count')\n",
    ")\n",
    "display(weather_coords)\n",
    "\n",
    "# Show sample data for each load_id\n",
    "print(\"\\nSample data for each load_id:\")\n",
    "for load_id_row in weather.select('load_id').distinct().collect():\n",
    "    load_id = load_id_row['load_id']\n",
    "    print(f\"\\n--- Load ID: {load_id} ---\")\n",
    "    sample = weather.filter(F.col('load_id') == load_id).limit(5)\n",
    "    display(sample.select('timestamp', 'lat', 'lon', 'temperature_c', 'wind_speed', 'load_id'))\n",
    "\n",
    "# Check if coordinates match any known European regions\n",
    "print(\"\\nüó∫Ô∏è COORDINATE RANGES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"European coordinate reference:\")\n",
    "print(\"  Germany: lat 47-55¬∞N, lon 6-15¬∞E\")\n",
    "print(\"  France: lat 42-51¬∞N, lon -5-8¬∞E\")\n",
    "print(\"  Spain: lat 36-43¬∞N, lon -9-3¬∞E\")\n",
    "print(\"  Poland: lat 49-55¬∞N, lon 14-24¬∞E\")\n",
    "print(\"  Scandinavia: lat 55-71¬∞N, lon 5-31¬∞E\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99e2cfa8-40e4-47af-a230-038eb392191e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"MAPPING WEATHER COORDINATES TO COUNTRIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load weather table\n",
    "CATALOG = \"curlybyte_solutions_rawdata_europe_grid_load\"\n",
    "WEATHER_SCHEMA = \"european_weather_raw\"\n",
    "\n",
    "weather = spark.table(f\"{CATALOG}.{WEATHER_SCHEMA}.weather_hourly\")\n",
    "print(\"‚úì Weather table loaded\")\n",
    "\n",
    "# Step 1: Check how many UNIQUE coordinates we have first\n",
    "print(\"\\nStep 1: Counting unique coordinates...\")\n",
    "unique_coords_count = weather.select(\"lat\", \"lon\").distinct().count()\n",
    "print(f\"Unique lat/lon pairs: {unique_coords_count:,}\")\n",
    "\n",
    "if unique_coords_count > 10000:\n",
    "    print(\"‚ö†Ô∏è Too many unique coordinates! Let's use a smarter approach...\")\n",
    "    \n",
    "    # Sample coordinates instead (much faster)\n",
    "    print(\"\\nStep 2: Sampling coordinates for mapping...\")\n",
    "    coord_sample = weather.select(\"lat\", \"lon\").distinct().limit(1000).collect()\n",
    "    print(f\"Working with {len(coord_sample)} sample coordinates\")\n",
    "else:\n",
    "    print(\"‚úì Manageable number of coordinates!\")\n",
    "    coord_sample = weather.select(\"lat\", \"lon\").distinct().collect()\n",
    "\n",
    "# Step 3: Check if reverse_geocode is installed\n",
    "print(\"\\nStep 3: Installing reverse_geocode...\")\n",
    "import subprocess\n",
    "subprocess.check_call(['pip', 'install', 'reverse_geocode', '--break-system-packages'])\n",
    "\n",
    "import reverse_geocode\n",
    "\n",
    "# Step 4: Map coordinates to countries\n",
    "print(\"\\nStep 4: Mapping coordinates to countries...\")\n",
    "coord_list = [(float(row['lat']), float(row['lon'])) for row in coord_sample]\n",
    "\n",
    "print(\"Processing geocoding (this may take 1-2 minutes)...\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "countries = reverse_geocode.search(coord_list)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"‚úì Geocoding complete in {elapsed:.1f} seconds\")\n",
    "\n",
    "# Step 5: Create mapping DataFrame\n",
    "print(\"\\nStep 5: Creating coordinate-to-country mapping...\")\n",
    "mapping_data = [(coord[0], coord[1], loc['country_code']) for coord, loc in zip(coord_list, countries)]\n",
    "mapping_df = spark.createDataFrame(mapping_data, [\"lat\", \"lon\", \"country\"])\n",
    "\n",
    "display(mapping_df.limit(20))\n",
    "\n",
    "print(f\"\\nMapping created: {len(mapping_data)} coordinates mapped to countries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c69df511-9d55-4851-9d6b-ff9a94638024",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"ANALYZING COORDINATE-TO-COUNTRY MAPPING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show country distribution\n",
    "print(\"\\nCountries found in sample:\")\n",
    "country_counts = mapping_df.groupBy(\"country\").count().orderBy(\"count\", ascending=False)\n",
    "display(country_counts)\n",
    "\n",
    "# Show total unique countries\n",
    "total_countries = mapping_df.select(\"country\").distinct().count()\n",
    "print(f\"\\nTotal unique countries in sample: {total_countries}\")\n",
    "\n",
    "# Compare with our master dataset countries\n",
    "print(\"\\nCountries in our master dataset:\")\n",
    "master_countries = spark.table(\"workspace.default.power_grid_master\").select(\"country\").distinct()\n",
    "display(master_countries.orderBy(\"country\"))\n",
    "\n",
    "# Check overlap\n",
    "print(\"\\nChecking overlap between weather coords and our data...\")\n",
    "master_country_list = [row['country'] for row in master_countries.collect()]\n",
    "weather_country_list = [row['country'] for row in mapping_df.select(\"country\").distinct().collect()]\n",
    "\n",
    "overlap = set(master_country_list) & set(weather_country_list)\n",
    "print(f\"Overlapping countries: {len(overlap)}\")\n",
    "print(f\"Countries: {sorted(overlap)}\")\n",
    "\n",
    "# Decision time\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS:\")\n",
    "print(\"=\"*60)\n",
    "print(\"We have a working coordinate-to-country mapping!\")\n",
    "print(\"\\nOptions:\")\n",
    "print(\"1. ‚úÖ Apply this mapping to ALL weather data (will take ~30 min)\")\n",
    "print(\"2. ‚è© Skip weather for now, proceed with current dataset\")\n",
    "print(\"\\nYour choice?\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EDA_weather",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
