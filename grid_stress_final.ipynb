{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772feb22-c88d-4309-9369-1b020f3c0b29",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "EUROPEAN POWER GRID STRESS PREDICTION - MACHINE LEARNING MODEL\n",
    "================================================================================\n",
    "Author: Peter Leme\n",
    "Project: Capstone - European Power Grid Blackout Risk Prediction\n",
    "Dataset: European electricity and weather data (2023-2025)\n",
    "Objective: Predict grid stress scores (0-75) to forecast blackout risk\n",
    "\n",
    "STRESS SCORING SYSTEM:\n",
    "- Score = score_reserve_margin + score_load_error + score_T7 + score_T8\n",
    "- Range: 0-75 points (theoretical max: 100)\n",
    "- Interpretation:\n",
    "  * 0-24:   Normal operations (low stress)\n",
    "  * 25-49:  Moderate stress (single component triggered)\n",
    "  * 50-74:  High stress (multiple components, blackout risk)\n",
    "  * 75:     Critical stress (imminent blackout)\n",
    "\n",
    "DATA:\n",
    "- Train:      386,525 records (2023-01-01 to 2024-12-31)\n",
    "- Validation: 111,670 records (2025-01-01 to 2025-06-30)\n",
    "- Test:        53,599 records (2025-07-01 to 2025-11-07)\n",
    "- Total:      551,794 hourly records across 23 European countries\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Install required packages with pinned versions\n",
    "%pip install xgboost==2.0.3 lightgbm==4.1.0\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EUROPEAN GRID STRESS PREDICTION - MINIMAL FEATURE SET\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "print(\"✓ All libraries loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "947909c7-550c-4908-85b9-cc9b2e138db6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LOAD DATA & FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load pre-split datasets from Databricks\n",
    "train_df = spark.table(\"workspace.default.train_set\").toPandas()\n",
    "val_df = spark.table(\"workspace.default.validation_set\").toPandas()\n",
    "test_df = spark.table(\"workspace.default.test_set\").toPandas()\n",
    "\n",
    "print(f\"\\n✓ Data loaded: {train_df.shape[0] + val_df.shape[0] + test_df.shape[0]:,} total records\")\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create only essential features - no generation data\"\"\"\n",
    "    \n",
    "    # Extract temporal components\n",
    "    df['hour'] = df['index'].dt.hour\n",
    "    df['month'] = df['index'].dt.month\n",
    "    df['is_weekend'] = (df['index'].dt.dayofweek >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding for time (preserves circular nature)\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_df = create_features(train_df)\n",
    "val_df = create_features(val_df)\n",
    "test_df = create_features(test_df)\n",
    "\n",
    "print(\"✓ Created cyclical temporal features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7265baea-ca55-4f40-aa21-9555a0a9503e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE SELECTION - ESSENTIAL FEATURES ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define ONLY the essential features we want to use\n",
    "# No generation features - just load, weather, imports, and temporal\n",
    "features_to_use = [\n",
    "    # Country identifier\n",
    "    'country',\n",
    "    \n",
    "    # Load features (core operational data)\n",
    "    'Actual_Load',\n",
    "    'Forecasted_Load',\n",
    "    \n",
    "    # Import/Export (critical for grid stress)\n",
    "    'net_imports',\n",
    "    \n",
    "    # Weather features\n",
    "    'mean_temperature_c',\n",
    "    'mean_wind_speed',\n",
    "    'mean_ssrd',              # Solar radiation\n",
    "    'solar_forecast',\n",
    "    'wind_forecast',\n",
    "    \n",
    "    # Temporal features (cyclical)\n",
    "    'hour_sin',\n",
    "    'hour_cos',\n",
    "    'month_sin',\n",
    "    'month_cos',\n",
    "    'is_weekend'\n",
    "]\n",
    "\n",
    "# Extract features and target\n",
    "X_train = train_df[features_to_use].copy()\n",
    "X_val = val_df[features_to_use].copy()\n",
    "X_test = test_df[features_to_use].copy()\n",
    "\n",
    "y_train = train_df['grid_stress_score'].copy()\n",
    "y_val = val_df['grid_stress_score'].copy()\n",
    "y_test = test_df['grid_stress_score'].copy()\n",
    "\n",
    "print(f\"\\n✓ Selected {len(features_to_use)} essential features:\")\n",
    "print(\"  - Load: Actual_Load, Forecasted_Load\")\n",
    "print(\"  - Imports: net_imports\")\n",
    "print(\"  - Weather: temperature, wind, solar (5 features)\")\n",
    "print(\"  - Temporal: hour_sin/cos, month_sin/cos, is_weekend (5 features)\")\n",
    "print(\"  - Country: 1 categorical feature\")\n",
    "\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  X_val:   {X_val.shape}\")\n",
    "print(f\"  X_test:  {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40762e53-77d9-4c90-b17a-391104a9bb10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n[Step 1] Checking for missing values...\")\n",
    "train_missing = X_train.isnull().sum()\n",
    "features_with_missing = train_missing[train_missing > 0]\n",
    "\n",
    "if len(features_with_missing) > 0:\n",
    "    print(f\"  Features with missing values:\")\n",
    "    for feat, count in features_with_missing.items():\n",
    "        pct = (count / len(X_train)) * 100\n",
    "        print(f\"    - {feat}: {count:,} ({pct:.2f}%)\")\n",
    "    \n",
    "    # Fill missing values with median (better than 0 for weather/load data)\n",
    "    print(f\"\\n  Filling missing values with median...\")\n",
    "    X_train = X_train.fillna(X_train.median())\n",
    "    X_val = X_val.fillna(X_train.median())  # Use train median for val/test\n",
    "    X_test = X_test.fillna(X_train.median())\n",
    "    print(\"  ✓ Missing values filled with training set median\")\n",
    "else:\n",
    "    print(\"  ✓ No missing values found\")\n",
    "\n",
    "# One-hot encode country\n",
    "print(\"\\n[Step 2] Encoding country variable...\")\n",
    "X_train = pd.get_dummies(X_train, columns=['country'], prefix='country', drop_first=False)\n",
    "X_val = pd.get_dummies(X_val, columns=['country'], prefix='country', drop_first=False)\n",
    "X_test = pd.get_dummies(X_test, columns=['country'], prefix='country', drop_first=False)\n",
    "\n",
    "# Ensure all datasets have same columns\n",
    "all_columns = X_train.columns\n",
    "X_val = X_val.reindex(columns=all_columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=all_columns, fill_value=0)\n",
    "\n",
    "print(f\"  ✓ One-hot encoded 23 countries\")\n",
    "\n",
    "print(f\"\\n✓ Final clean dataset:\")\n",
    "print(f\"  X_train: {X_train.shape[0]:>8,} rows × {X_train.shape[1]:>2} features\")\n",
    "print(f\"  X_val:   {X_val.shape[0]:>8,} rows × {X_val.shape[1]:>2} features\")\n",
    "print(f\"  X_test:  {X_test.shape[0]:>8,} rows × {X_test.shape[1]:>2} features\")\n",
    "print(f\"  Features: 13 numeric + 23 country indicators = {X_train.shape[1]} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73f9ced3-aaf5-430a-ba49-5be9b9acc614",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTesting multiple algorithms to find best performer...\\n\")\n",
    "\n",
    "# Define models to test\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=20, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=20, \n",
    "        min_samples_split=5,\n",
    "        random_state=42, \n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100, \n",
    "        max_depth=7, \n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=7,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Train and evaluate all models\n",
    "results = []\n",
    "\n",
    "print(f\"{'Model':<20} {'Train Time':>12} {'Val MAE':>10} {'Val RMSE':>10} {'Val R²':>10}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Train model\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train_Time': train_time,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'model_object': model\n",
    "    })\n",
    "    \n",
    "    print(f\"{model_name:<20} {train_time:>10.2f}s {mae:>10.3f} {rmse:>10.3f} {r2:>10.4f}\")\n",
    "\n",
    "# Find best model\n",
    "results_df = pd.DataFrame(results)\n",
    "best_idx = results_df['R2'].idxmax()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_model = results_df.loc[best_idx, 'model_object']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 75)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"  Validation MAE:  {results_df.loc[best_idx, 'MAE']:.3f} points\")\n",
    "print(f\"  Validation RMSE: {results_df.loc[best_idx, 'RMSE']:.3f} points\")\n",
    "print(f\"  Validation R²:   {results_df.loc[best_idx, 'R2']:.4f}\")\n",
    "print(\"=\" * 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52648544-6faa-41d7-a8ac-c2663cfd51df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL MODEL EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nEvaluating {best_model_name} on all datasets:\\n\")\n",
    "\n",
    "# Evaluate on all splits\n",
    "evaluation_results = {}\n",
    "\n",
    "for split_name, X, y in [('Train', X_train, y_train),\n",
    "                          ('Validation', X_val, y_val),\n",
    "                          ('Test', X_test, y_test)]:\n",
    "    y_pred = best_model.predict(X)\n",
    "    \n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    evaluation_results[split_name] = {'MAE': mae, 'RMSE': rmse, 'R2': r2}\n",
    "    \n",
    "    print(f\"{split_name} Set:\")\n",
    "    print(f\"  MAE:  {mae:>8.3f} points\")\n",
    "    print(f\"  RMSE: {rmse:>8.3f} points\")\n",
    "    print(f\"  R²:   {r2:>8.4f}\")\n",
    "    print()\n",
    "\n",
    "# Check for overfitting\n",
    "train_r2 = evaluation_results['Train']['R2']\n",
    "val_r2 = evaluation_results['Validation']['R2']\n",
    "r2_diff = train_r2 - val_r2\n",
    "\n",
    "if r2_diff > 0.1:\n",
    "    print(f\"⚠️  Warning: Some overfitting detected\")\n",
    "    print(f\"   Train R² ({train_r2:.4f}) - Val R² ({val_r2:.4f}) = {r2_diff:.4f}\")\n",
    "else:\n",
    "    print(f\"✓ Model generalizes well (Train-Val R² diff: {r2_diff:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6b6c92f-2db4-471e-9b82-df82a5b1e84a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get feature importance from Random Forest\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': best_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 20 Most Important Features:\\n\")\n",
    "print(f\"{'Rank':<6} {'Feature':<45} {'Importance':>12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for idx, (_, row) in enumerate(importance_df.head(20).iterrows(), 1):\n",
    "    print(f\"{idx:<6} {row['Feature']:<45} {row['Importance']:>12.6f}\")\n",
    "\n",
    "# Check importance of key features\n",
    "print(\"\\n\" + \"-\" * 65)\n",
    "print(\"Key Feature Rankings:\")\n",
    "for key_feat in ['Actual_Load', 'Forecasted_Load', 'net_imports', 'mean_temperature_c']:\n",
    "    if key_feat in importance_df['Feature'].values:\n",
    "        rank = importance_df[importance_df['Feature'] == key_feat].index[0] + 1\n",
    "        imp = importance_df[importance_df['Feature'] == key_feat]['Importance'].values[0]\n",
    "        print(f\"  {key_feat:<25} Rank #{rank:<3} Importance: {imp:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f738cf9-2e8f-4fad-9188-95f46c6a78d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODEL TRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\"\"\n",
    "✓ MODELING COMPLETE\n",
    "\n",
    "APPROACH:\n",
    "- Minimal feature set: Only essential operational and weather data\n",
    "- No energy generation features (avoided missing data complexity)\n",
    "- Total features: 36 (13 numeric + 23 country indicators)\n",
    "\n",
    "FINAL MODEL: {best_model_name}\n",
    "- Validation MAE: {evaluation_results['Validation']['MAE']:.3f} points\n",
    "- Validation R²:  {evaluation_results['Validation']['R2']:.4f}\n",
    "- Test MAE:       {evaluation_results['Test']['MAE']:.3f} points\n",
    "- Test R²:        {evaluation_results['Test']['R2']:.4f}\n",
    "\n",
    "PERFORMANCE INTERPRETATION:\n",
    "- MAE of {evaluation_results['Validation']['MAE']:.1f} points means predictions are typically \n",
    "  within ±{evaluation_results['Validation']['MAE']:.1f} points of actual stress\n",
    "- On a 0-75 scale with thresholds at 25, 50, 75:\n",
    "  * Can reliably distinguish normal (0-24) from stressed (25+)\n",
    "  * Good accuracy for moderate stress detection (25-49)\n",
    "  * Adequate warning capability for high stress (50+)\n",
    "\n",
    "TOP 3 MOST IMPORTANT FEATURES:\n",
    "1. net_imports (28% importance) - Grid import/export balance\n",
    "2. Actual_Load (10% importance) - Current electricity demand\n",
    "3. Forecasted_Load (8% importance) - Predicted demand\n",
    "\n",
    "CONCLUSION:\n",
    "Model successfully predicts grid stress with good accuracy using only\n",
    "essential operational features. Ready for deployment.\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fec3f58-a92e-4338-b547-321f9abd620c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create figure with subplots\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Get predictions for test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 1: Actual vs Predicted (Top Left)\n",
    "# ============================================================================\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "ax1.scatter(y_test, y_test_pred, alpha=0.5, s=10)\n",
    "ax1.plot([0, 75], [0, 75], 'r--', label='Perfect Prediction', linewidth=2)\n",
    "ax1.set_xlabel('Actual Grid Stress Score', fontsize=10)\n",
    "ax1.set_ylabel('Predicted Grid Stress Score', fontsize=10)\n",
    "ax1.set_title('Actual vs Predicted (Test Set)', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "# Add R² text\n",
    "r2_test = r2_score(y_test, y_test_pred)\n",
    "ax1.text(0.05, 0.95, f'R² = {r2_test:.4f}', transform=ax1.transAxes, \n",
    "         fontsize=10, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 2: Residuals Plot (Top Right)\n",
    "# ============================================================================\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "residuals = y_test - y_test_pred\n",
    "ax2.scatter(y_test_pred, residuals, alpha=0.5, s=10)\n",
    "ax2.axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Predicted Grid Stress Score', fontsize=10)\n",
    "ax2.set_ylabel('Residuals', fontsize=10)\n",
    "ax2.set_title('Residuals Plot', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 3: Residuals Distribution (Bottom Left)\n",
    "# ============================================================================\n",
    "ax3 = plt.subplot(2, 3, 4)\n",
    "ax3.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax3.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "ax3.set_xlabel('Residuals', fontsize=10)\n",
    "ax3.set_ylabel('Frequency', fontsize=10)\n",
    "ax3.set_title('Residuals Distribution', fontsize=12, fontweight='bold')\n",
    "# Add mean and std text\n",
    "mean_res = np.mean(residuals)\n",
    "std_res = np.std(residuals)\n",
    "ax3.text(0.05, 0.95, f'Mean: {mean_res:.4f}\\nStd: {std_res:.4f}', \n",
    "         transform=ax3.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 4: Model Comparison (Bottom Right)\n",
    "# ============================================================================\n",
    "ax4 = plt.subplot(2, 3, 5)\n",
    "# Get test R² for all models\n",
    "model_names = []\n",
    "model_r2_scores = []\n",
    "for _, row in results_df.iterrows():\n",
    "    model_names.append(row['Model'])\n",
    "    y_pred_model = row['model_object'].predict(X_test)\n",
    "    r2_model = r2_score(y_test, y_pred_model)\n",
    "    model_r2_scores.append(r2_model)\n",
    "\n",
    "# Create horizontal bar chart\n",
    "colors = ['green' if name == best_model_name else 'skyblue' for name in model_names]\n",
    "bars = ax4.barh(model_names, model_r2_scores, color=colors, edgecolor='black')\n",
    "ax4.set_xlabel('R² Score', fontsize=10)\n",
    "ax4.set_title('Model Comparison (Test R²)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlim(0, 1.0)\n",
    "# Add value labels\n",
    "for i, (bar, score) in enumerate(zip(bars, model_r2_scores)):\n",
    "    ax4.text(score + 0.02, i, f'{score:.4f}', va='center', fontsize=9)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 5: Feature Importance (Top 15)\n",
    "# ============================================================================\n",
    "ax5 = plt.subplot(2, 3, 3)\n",
    "top_features = importance_df.head(15).sort_values('Importance', ascending=True)\n",
    "bars = ax5.barh(range(len(top_features)), top_features['Importance'], color='steelblue', edgecolor='black')\n",
    "ax5.set_yticks(range(len(top_features)))\n",
    "ax5.set_yticklabels(top_features['Feature'], fontsize=9)\n",
    "ax5.set_xlabel('Importance', fontsize=10)\n",
    "ax5.set_title('Top 15 Feature Importance - Random Forest', fontsize=12, fontweight='bold')\n",
    "# Add value labels\n",
    "for i, (bar, imp) in enumerate(zip(bars, top_features['Importance'])):\n",
    "    ax5.text(imp + 0.005, i, f'{imp:.4f}', va='center', fontsize=8)\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 6: Classification Comparison (if threshold = 50)\n",
    "# ============================================================================\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "# Create binary classification: High Risk (>=50) vs Low Risk (<50)\n",
    "threshold = 50\n",
    "y_test_binary = (y_test >= threshold).astype(int)\n",
    "y_pred_binary = (y_test_pred >= threshold).astype(int)\n",
    "\n",
    "# Count classes\n",
    "actual_counts = [np.sum(y_test_binary == 0), np.sum(y_test_binary == 1)]\n",
    "pred_counts = [np.sum(y_pred_binary == 0), np.sum(y_pred_binary == 1)]\n",
    "\n",
    "x = np.arange(2)\n",
    "width = 0.35\n",
    "bars1 = ax6.bar(x - width/2, actual_counts, width, label='Actual', color='cornflowerblue', edgecolor='black')\n",
    "bars2 = ax6.bar(x + width/2, pred_counts, width, label='Predicted', color='coral', edgecolor='black')\n",
    "\n",
    "ax6.set_xlabel('Class', fontsize=10)\n",
    "ax6.set_ylabel('Count', fontsize=10)\n",
    "ax6.set_title('Class Distribution: Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "ax6.set_xticks(x)\n",
    "ax6.set_xticklabels([f'Low Risk (<{threshold})', f'High Risk (>={threshold})'])\n",
    "ax6.legend()\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}', ha='center', va='bottom', fontsize=9)\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height):,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Regression Model Evaluation - Random Forest', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Visualizations created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "999e052e-3fc4-40e4-971d-0857bf80213c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CORRELATION ANALYSIS & CONFUSION MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create figure\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 1: Correlation Heatmap (numeric features only)\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 1] Generating correlation matrix...\")\n",
    "\n",
    "# Select only numeric features (exclude country dummy variables)\n",
    "numeric_features = ['Actual_Load', 'Forecasted_Load', 'net_imports', \n",
    "                   'mean_temperature_c', 'mean_wind_speed', 'mean_ssrd',\n",
    "                   'solar_forecast', 'wind_forecast',\n",
    "                   'hour_sin', 'hour_cos', 'month_sin', 'month_cos', 'is_weekend']\n",
    "\n",
    "# Create correlation matrix with target\n",
    "correlation_data = train_df[numeric_features + ['grid_stress_score']].copy()\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "            ax=ax1, vmin=-1, vmax=1)\n",
    "ax1.set_title('Feature Correlation Matrix\\n(includes grid_stress_score)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "plt.setp(ax1.get_yticklabels(), rotation=0, fontsize=9)\n",
    "\n",
    "print(\"✓ Correlation matrix generated\")\n",
    "\n",
    "# ============================================================================\n",
    "# PLOT 2: Confusion Matrix for Binary Classification\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 2] Creating confusion matrix...\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Define threshold for high stress (blackout risk)\n",
    "threshold = 50\n",
    "\n",
    "# Create binary labels: 0 = Low Risk (<50), 1 = High Risk (>=50)\n",
    "y_test_binary = (y_test >= threshold).astype(int)\n",
    "y_pred_binary = (y_test_pred >= threshold).astype(int)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
    "\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Low Risk', 'High Risk'],\n",
    "            yticklabels=['Low Risk', 'High Risk'],\n",
    "            cbar_kws={\"shrink\": 0.8}, ax=ax2, linewidths=2, linecolor='black')\n",
    "\n",
    "ax2.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax2.set_title(f'Confusion Matrix (Test Set)\\nThreshold: {threshold} points', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add percentage annotations\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        text = ax2.texts[i*2 + j]\n",
    "        count = cm[i, j]\n",
    "        percentage = count / cm.sum() * 100\n",
    "        text.set_text(f'{count:,}\\n({percentage:.1f}%)')\n",
    "        text.set_fontsize(11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix created\")\n",
    "\n",
    "# ============================================================================\n",
    "# Classification Metrics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASSIFICATION METRICS (Binary: High Risk >= 50)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "precision = precision_score(y_test_binary, y_pred_binary)\n",
    "recall = recall_score(y_test_binary, y_pred_binary)\n",
    "f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"  - True Negatives (Low Risk correctly predicted):  {cm[0,0]:,}\")\n",
    "print(f\"  - False Positives (Low Risk predicted as High):   {cm[0,1]:,}\")\n",
    "print(f\"  - False Negatives (High Risk predicted as Low):   {cm[1,0]:,}\")\n",
    "print(f\"  - True Positives (High Risk correctly predicted): {cm[1,1]:,}\")\n",
    "\n",
    "# Calculate percentages\n",
    "tn_pct = cm[0,0] / (cm[0,0] + cm[0,1]) * 100\n",
    "tp_pct = cm[1,1] / (cm[1,0] + cm[1,1]) * 100\n",
    "\n",
    "print(f\"\\n  - {tn_pct:.1f}% of low risk cases correctly identified\")\n",
    "print(f\"  - {tp_pct:.1f}% of high risk cases correctly identified\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "grid_stress_final",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
