{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f801a355-70fd-4879-bff2-5cecc3fd9979",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "EUROPEAN POWER GRID STRESS PREDICTION - PRODUCTION MODEL\n",
    "================================================================================\n",
    "Project: Capstone - Blackout Risk Prediction\n",
    "Date: November 2025\n",
    "\n",
    "OBJECTIVE:\n",
    "Predict grid stress scores (0-75) for European power grids using only\n",
    "legitimate operational features available in real-time.\n",
    "\n",
    "DATA LEAKAGE PREVENTION:\n",
    "Excluded features that create circular dependencies:\n",
    "- net_imports: Used to calculate T7/T8 components of target\n",
    "- stress_lag_*: Using target to predict target\n",
    "- reserve_margin_ml, forecast_load_error: Components of target scoring\n",
    "\n",
    "LEGITIMATE FEATURES USED:\n",
    "- Load data: Actual and forecasted electricity demand\n",
    "- Weather: Temperature, wind speed, solar radiation\n",
    "- Temporal: Hour, day, week patterns (cyclical encoding)\n",
    "- Historical: Lag features of load, imports, temperature (past values)\n",
    "- Derived: Rolling statistics, load-weather interactions\n",
    "\n",
    "TARGET: grid_stress_score (0-75 points)\n",
    "- 0-24: Normal operations\n",
    "- 25-49: Moderate stress\n",
    "- 50-74: High stress (blackout risk)\n",
    "- 75: Critical\n",
    "\n",
    "DATASET:\n",
    "- Train: 386,525 records (2023-2024)\n",
    "- Validation: 111,670 records (Jan-Jul 2025)\n",
    "- Test: 53,599 records (Aug-Nov 2025)\n",
    "- Countries: 23 European nations\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# Install packages\n",
    "%pip install xgboost==2.0.3 lightgbm==4.1.0\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EUROPEAN GRID STRESS PREDICTION - PRODUCTION MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c841218f-e296-4fcd-8ded-8870838bca88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 1: DATA LOADING & INITIAL EXPLORATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load datasets\n",
    "train_df = spark.table(\"workspace.default.train_set_imputed\").toPandas()\n",
    "val_df = spark.table(\"workspace.default.validation_set_imputed\").toPandas()\n",
    "test_df = spark.table(\"workspace.default.test_set_imputed\").toPandas()\n",
    "\n",
    "print(f\"\\n✓ Data loaded: {train_df.shape[0] + val_df.shape[0] + test_df.shape[0]:,} total records\")\n",
    "print(f\"  Train:      {train_df.shape[0]:>8,} rows × {train_df.shape[1]:>2} columns\")\n",
    "print(f\"  Validation: {val_df.shape[0]:>8,} rows × {val_df.shape[1]:>2} columns\")\n",
    "print(f\"  Test:       {test_df.shape[0]:>8,} rows × {test_df.shape[1]:>2} columns\")\n",
    "\n",
    "# Target analysis\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TARGET VARIABLE: grid_stress_score\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nDistribution Statistics:\")\n",
    "print(f\"  Mean:   {train_df['grid_stress_score'].mean():.2f}\")\n",
    "print(f\"  Median: {train_df['grid_stress_score'].median():.2f}\")\n",
    "print(f\"  Std:    {train_df['grid_stress_score'].std():.2f}\")\n",
    "print(f\"  Range:  [{train_df['grid_stress_score'].min():.1f}, {train_df['grid_stress_score'].max():.1f}]\")\n",
    "\n",
    "print(f\"\\nValue Distribution:\")\n",
    "stress_counts = train_df['grid_stress_score'].value_counts().sort_index()\n",
    "for score, count in stress_counts.items():\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    category = \"NORMAL\" if score < 25 else \"MODERATE\" if score < 50 else \"HIGH RISK\"\n",
    "    print(f\"  {score:>5.1f}: {count:>8,} ({pct:>5.2f}%) - {category}\")\n",
    "\n",
    "# Temporal coverage\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TEMPORAL COVERAGE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, df in [('Train', train_df), ('Validation', val_df), ('Test', test_df)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Start: {df['index'].min()}\")\n",
    "    print(f\"  End:   {df['index'].max()}\")\n",
    "    print(f\"  Days:  {(df['index'].max() - df['index'].min()).days}\")\n",
    "\n",
    "# Country distribution\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"COUNTRY DISTRIBUTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "country_counts = train_df['country'].value_counts()\n",
    "print(f\"\\nTotal countries: {len(country_counts)}\")\n",
    "print(f\"\\nRecords per country:\")\n",
    "for country, count in country_counts.items():\n",
    "    pct = (count / len(train_df)) * 100\n",
    "    avg_stress = train_df[train_df['country'] == country]['grid_stress_score'].mean()\n",
    "    print(f\"  {country:>2}: {count:>8,} ({pct:>4.2f}%) - Avg stress: {avg_stress:>5.2f}\")\n",
    "\n",
    "print(\"\\n✓ Initial exploration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4a72ab1-57c4-46d6-ba8f-704180513dbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 2: FEATURE ENGINEERING (NO LEAKAGE)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def create_clean_features(df):\n",
    "    \"\"\"\n",
    "    Create features WITHOUT any data leakage.\n",
    "    Excludes: net_imports, stress_lag_*, reserve_margin_ml, forecast_load_error\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nSorting data by country and time...\")\n",
    "    df = df.sort_values(['country', 'index']).reset_index(drop=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # TEMPORAL FEATURES\n",
    "    # ========================================================================\n",
    "    print(\"Creating temporal features...\")\n",
    "    \n",
    "    df['hour'] = df['index'].dt.hour\n",
    "    df['month'] = df['index'].dt.month\n",
    "    df['day_of_week'] = df['index'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "    df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "    df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "    \n",
    "    # Peak hours\n",
    "    df['is_morning_peak'] = df['hour'].isin([7, 8, 9]).astype(int)\n",
    "    df['is_evening_peak'] = df['hour'].isin([18, 19, 20, 21]).astype(int)\n",
    "    df['is_peak_hour'] = (df['is_morning_peak'] | df['is_evening_peak']).astype(int)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # LAG FEATURES (Using past values only - NO stress lags!)\n",
    "    # ========================================================================\n",
    "    print(\"Creating lag features (load, imports, temperature)...\")\n",
    "    \n",
    "    # Load lags\n",
    "    for lag in [1, 24]:\n",
    "        df[f'load_lag_{lag}h'] = df.groupby('country')['Actual_Load'].shift(lag)\n",
    "    \n",
    "    # Import lags (using past net_imports - legitimate!)\n",
    "    df['imports_lag_1h'] = df.groupby('country')['net_imports'].shift(1)\n",
    "    \n",
    "    # Temperature lags\n",
    "    df['temp_lag_1h'] = df.groupby('country')['mean_temperature_c'].shift(1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ROLLING STATISTICS\n",
    "    # ========================================================================\n",
    "    print(\"Creating rolling statistics...\")\n",
    "    \n",
    "    df['load_rolling_mean_24h'] = df.groupby('country')['Actual_Load'].transform(\n",
    "        lambda x: x.rolling(window=24, min_periods=1).mean()\n",
    "    )\n",
    "    df['load_rolling_std_24h'] = df.groupby('country')['Actual_Load'].transform(\n",
    "        lambda x: x.rolling(window=24, min_periods=1).std()\n",
    "    )\n",
    "    \n",
    "    df['imports_rolling_mean_24h'] = df.groupby('country')['net_imports'].transform(\n",
    "        lambda x: x.shift(1).rolling(window=24, min_periods=1).mean()\n",
    "    )\n",
    "    \n",
    "    # Change features\n",
    "    df['load_change_1h'] = df.groupby('country')['Actual_Load'].diff(1)\n",
    "    df['load_change_24h'] = df.groupby('country')['Actual_Load'].diff(24)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # INTERACTION FEATURES\n",
    "    # ========================================================================\n",
    "    print(\"Creating interaction features...\")\n",
    "    \n",
    "    # Load-forecast interactions\n",
    "    df['load_forecast_diff'] = df['Actual_Load'] - df['Forecasted_Load']\n",
    "    df['load_forecast_ratio'] = df['Actual_Load'] / (df['Forecasted_Load'] + 1e-6)\n",
    "    df['load_forecast_error_pct'] = np.abs(df['load_forecast_diff']) / (df['Forecasted_Load'] + 1e-6) * 100\n",
    "    \n",
    "    # Weather-load interactions\n",
    "    df['load_per_temp'] = df['Actual_Load'] / (df['mean_temperature_c'] + 20)\n",
    "    df['temp_load_product'] = df['mean_temperature_c'] * df['Actual_Load'] / 10000\n",
    "    \n",
    "    # Weather extremes\n",
    "    df['is_very_cold'] = (df['mean_temperature_c'] < 0).astype(int)\n",
    "    df['temp_extreme'] = df['is_very_cold'].astype(int)\n",
    "    \n",
    "    # Wind power potential\n",
    "    df['wind_power_index'] = df['mean_wind_speed'] ** 3 / 100\n",
    "    \n",
    "    # ========================================================================\n",
    "    # SEASONALITY\n",
    "    # ========================================================================\n",
    "    print(\"Creating seasonality features...\")\n",
    "    \n",
    "    df['hourly_avg_load'] = df.groupby(['country', 'hour'])['Actual_Load'].transform('mean')\n",
    "    df['load_deviation_from_hourly_avg'] = df['Actual_Load'] - df['hourly_avg_load']\n",
    "    \n",
    "    df['daily_avg_load'] = df.groupby(['country', 'day_of_week'])['Actual_Load'].transform('mean')\n",
    "    df['load_deviation_from_daily_avg'] = df['Actual_Load'] - df['daily_avg_load']\n",
    "    \n",
    "    print(\"✓ Feature engineering complete\\n\")\n",
    "    return df\n",
    "\n",
    "# Apply to all datasets\n",
    "print(\"Applying feature engineering...\")\n",
    "train_df = create_clean_features(train_df)\n",
    "val_df = create_clean_features(val_df)\n",
    "test_df = create_clean_features(test_df)\n",
    "\n",
    "print(f\"✓ Feature engineering complete\")\n",
    "print(f\"  Total columns: {train_df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c931d49-f454-46e3-be6a-4a6d99cad6d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 3: COMPREHENSIVE EDA & CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Define clean feature set (exclude leakage and metadata)\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 1] Defining clean feature set...\")\n",
    "\n",
    "LEAKAGE_COLS = [\n",
    "    # Metadata\n",
    "    'index', 'country',\n",
    "    # Target\n",
    "    'grid_stress_score',\n",
    "    # Data leakage - components of target\n",
    "    'reserve_margin_ml', 'forecast_load_error', 'load_rel_error',\n",
    "    'net_imports',  # Used to calculate T7/T8\n",
    "    'P10_net', 'P90_net',  # Thresholds\n",
    "    'score_reserve_margin', 'score_load_error', 'score_T7', 'score_T8',\n",
    "    'T7_high_exports', 'T8_high_imports',\n",
    "    # Redundant temporal\n",
    "    'hour', 'month', 'day_of_week'\n",
    "]\n",
    "\n",
    "# Get feature candidates\n",
    "all_cols = train_df.columns.tolist()\n",
    "feature_candidates = [col for col in all_cols if col not in LEAKAGE_COLS]\n",
    "\n",
    "print(f\"  Total columns: {len(all_cols)}\")\n",
    "print(f\"  Excluded: {len(LEAKAGE_COLS)}\")\n",
    "print(f\"  Feature candidates: {len(feature_candidates)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Select numeric features for correlation\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 3] Preparing numeric features for correlation analysis...\")\n",
    "\n",
    "numeric_features = []\n",
    "for col in feature_candidates:\n",
    "    if train_df[col].dtype in ['int64', 'float64']:\n",
    "        missing_pct = train_df[col].isnull().sum() / len(train_df)\n",
    "        if missing_pct < 0.80:  # Keep if <80% missing\n",
    "            numeric_features.append(col)\n",
    "\n",
    "# ============================================================================\n",
    "# Calculate correlations with target\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 4] Calculating correlations with target...\")\n",
    "\n",
    "correlations = {}\n",
    "for feat in numeric_features:\n",
    "    valid_count = train_df[feat].notna().sum()\n",
    "    if valid_count > 100:\n",
    "        corr = train_df[feat].corr(train_df['grid_stress_score'])\n",
    "        if not np.isnan(corr):\n",
    "            correlations[feat] = corr\n",
    "\n",
    "corr_df = pd.DataFrame.from_dict(correlations, orient='index', columns=['Correlation'])\n",
    "corr_df['Abs_Correlation'] = corr_df['Correlation'].abs()\n",
    "corr_df = corr_df.sort_values('Abs_Correlation', ascending=False)\n",
    "\n",
    "print(f\"\\nTop 25 Features by Correlation with grid_stress_score:\")\n",
    "print(f\"\\n{'Rank':<6} {'Feature':<50} {'Correlation':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for idx, (feat, row) in enumerate(corr_df.head(25).iterrows(), 1):\n",
    "    print(f\"{idx:<6} {feat:<50} {row['Correlation']:>12.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: Correlation Heatmap - Top Features\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 5] Creating correlation matrix visualization...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "\n",
    "# Plot 1: Correlation heatmap of top 20 features + target\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "top_20_features = corr_df.head(20).index.tolist()\n",
    "heatmap_data = train_df[top_20_features + ['grid_stress_score']].corr()\n",
    "\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "            ax=ax1, vmin=-1, vmax=1, annot_kws={'size': 7})\n",
    "ax1.set_title('Correlation Matrix: Top 20 Features + Target', \n",
    "              fontsize=14, fontweight='bold', pad=15)\n",
    "plt.setp(ax1.get_xticklabels(), rotation=45, ha='right', fontsize=8)\n",
    "plt.setp(ax1.get_yticklabels(), rotation=0, fontsize=8)\n",
    "\n",
    "# Plot 2: Feature importance by correlation (bar chart)\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "top_20 = corr_df.head(20).sort_values('Correlation', ascending=True)\n",
    "colors = ['red' if x < 0 else 'green' for x in top_20['Correlation']]\n",
    "bars = ax2.barh(range(len(top_20)), top_20['Correlation'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.set_yticks(range(len(top_20)))\n",
    "ax2.set_yticklabels(top_20.index, fontsize=8)\n",
    "ax2.set_xlabel('Correlation with grid_stress_score', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Top 20 Features by Correlation', fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, top_20['Correlation'])):\n",
    "    ax2.text(val + 0.01 if val > 0 else val - 0.01, i, f'{val:.3f}', \n",
    "             va='center', fontsize=7, fontweight='bold')\n",
    "\n",
    "\n",
    "# Plot 3: Target distribution\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "ax3.hist(train_df['grid_stress_score'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax3.axvline(x=25, color='orange', linestyle='--', linewidth=2, label='Moderate (25)')\n",
    "ax3.axvline(x=50, color='red', linestyle='--', linewidth=2, label='High Risk (50)')\n",
    "ax3.set_xlabel('Grid Stress Score', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Target Distribution', fontsize=14, fontweight='bold', pad=15)\n",
    "ax3.legend(fontsize=10)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "mean_val = train_df['grid_stress_score'].mean()\n",
    "median_val = train_df['grid_stress_score'].median()\n",
    "ax3.text(0.98, 0.97, f'Mean: {mean_val:.2f}\\nMedian: {median_val:.2f}',\n",
    "         transform=ax3.transAxes, fontsize=10, verticalalignment='top',\n",
    "         horizontalalignment='right', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Plot 4: Country stress comparison\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "country_stress = train_df.groupby('country')['grid_stress_score'].mean().sort_values(ascending=True)\n",
    "colors_country = ['red' if x > 35 else 'orange' if x > 28 else 'green' for x in country_stress.values]\n",
    "bars = ax4.barh(range(len(country_stress)), country_stress.values, color=colors_country, alpha=0.7, edgecolor='black')\n",
    "ax4.set_yticks(range(len(country_stress)))\n",
    "ax4.set_yticklabels(country_stress.index, fontsize=8)\n",
    "ax4.set_xlabel('Average Grid Stress Score', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Average Stress by Country', fontsize=14, fontweight='bold', pad=15)\n",
    "ax4.axvline(x=mean_val, color='black', linestyle='--', linewidth=1.5, alpha=0.5, \n",
    "            label=f'Overall Avg ({mean_val:.1f})')\n",
    "ax4.legend(fontsize=9)\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, country_stress.values)):\n",
    "    ax4.text(val + 0.5, i, f'{val:.1f}', va='center', fontsize=7)\n",
    "\n",
    "plt.suptitle('European Grid Stress Prediction - Exploratory Data Analysis', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/eda.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Correlation matrix and distributions created\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: Time Series Patterns\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 6] Creating time series pattern analysis...\")\n",
    "\n",
    "fig2 = plt.figure(figsize=(20, 10))\n",
    "\n",
    "sample_country = 'DE'\n",
    "sample_data = train_df[train_df['country'] == sample_country].sort_values('index').head(168*2)\n",
    "\n",
    "ax5 = plt.subplot(3, 1, 1)\n",
    "ax5.plot(sample_data['index'], sample_data['grid_stress_score'], linewidth=1.5, color='darkblue')\n",
    "ax5.axhline(y=50, color='red', linestyle='--', linewidth=2, label='High Risk (50)')\n",
    "ax5.axhline(y=25, color='orange', linestyle='--', linewidth=2, alpha=0.5, label='Moderate (25)')\n",
    "ax5.set_ylabel('Grid Stress Score', fontsize=11, fontweight='bold')\n",
    "ax5.set_title(f'Grid Stress Time Series - {sample_country} (2 weeks)', fontsize=14, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(alpha=0.3)\n",
    "plt.savefig('../images/stress_per_country.png')\n",
    "\n",
    "ax6 = plt.subplot(3, 1, 2)\n",
    "ax6.plot(sample_data['index'], sample_data['Actual_Load'], linewidth=1.5, color='green', label='Actual Load')\n",
    "ax6.plot(sample_data['index'], sample_data['Forecasted_Load'], linewidth=1.5, color='orange', \n",
    "         linestyle='--', label='Forecasted Load')\n",
    "ax6.set_ylabel('Load (MW)', fontsize=11, fontweight='bold')\n",
    "ax6.set_title('Load: Actual vs Forecasted', fontsize=14, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(alpha=0.3)\n",
    "\n",
    "ax7 = plt.subplot(3, 1, 3)\n",
    "ax7.plot(sample_data['index'], sample_data['mean_temperature_c'], linewidth=1.5, color='red', label='Temperature')\n",
    "ax7_twin = ax7.twinx()\n",
    "ax7_twin.plot(sample_data['index'], sample_data['mean_wind_speed'], linewidth=1.5, color='blue', label='Wind Speed')\n",
    "ax7.set_ylabel('Temperature (°C)', fontsize=11, fontweight='bold', color='red')\n",
    "ax7_twin.set_ylabel('Wind Speed (m/s)', fontsize=11, fontweight='bold', color='blue')\n",
    "ax7.set_xlabel('Time', fontsize=11, fontweight='bold')\n",
    "ax7.set_title('Weather Conditions', fontsize=14, fontweight='bold')\n",
    "ax7.legend(loc='upper left')\n",
    "ax7_twin.legend(loc='upper right')\n",
    "ax7.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/eda_time_series.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Time series patterns visualized\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDA COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a68bbfd4-510a-4e57-a004-c102c3183cbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 4: DATA PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Select final features (keep best performers, remove redundant)\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 2] Selecting final feature set...\")\n",
    "\n",
    "# Keep only essential features\n",
    "features_to_keep = [\n",
    "    # Load features\n",
    "    'Actual_Load', 'Forecasted_Load',\n",
    "    \n",
    "    # Load lags\n",
    "    'load_lag_1h', 'load_lag_24h',\n",
    "    \n",
    "    # Load derived\n",
    "    'load_rolling_mean_24h', 'load_rolling_std_24h',\n",
    "    'load_change_1h', 'load_change_24h',\n",
    "    'load_forecast_diff', 'load_forecast_ratio', 'load_forecast_error_pct',\n",
    "    'load_deviation_from_hourly_avg', 'load_deviation_from_daily_avg',\n",
    "    \n",
    "    # Weather features\n",
    "    'mean_temperature_c', 'mean_wind_speed', 'mean_ssrd',\n",
    "    'solar_forecast', 'wind_forecast',\n",
    "    'temp_lag_1h',\n",
    "    \n",
    "    # Weather derived\n",
    "    'load_per_temp', 'temp_load_product', 'is_very_cold', 'temp_extreme',\n",
    "    'wind_power_index',\n",
    "    \n",
    "    # Import features (past values only!)\n",
    "    'imports_lag_1h',\n",
    "    'imports_rolling_mean_24h',\n",
    "    \n",
    "    # Temporal features\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'month_sin', 'month_cos',\n",
    "    'day_of_week_sin', 'day_of_week_cos',\n",
    "    'is_weekend', 'is_morning_peak', 'is_evening_peak', 'is_peak_hour',\n",
    "    \n",
    "    # Country\n",
    "    'country'\n",
    "]\n",
    "\n",
    "# Add any generation features that aren't too sparse\n",
    "generation_features = [f for f in feature_candidates \n",
    "                      if 'Actual_Aggregated' in f \n",
    "                      and train_df[f].isnull().sum() / len(train_df) < 0.80]\n",
    "\n",
    "final_features = features_to_keep + generation_features\n",
    "\n",
    "# Remove any that don't exist\n",
    "final_features = [f for f in final_features if f in train_df.columns]\n",
    "\n",
    "print(f\"  Selected {len(final_features)} features\")\n",
    "print(f\"    Core features: {len(features_to_keep)}\")\n",
    "print(f\"    Generation features: {len(generation_features)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Prepare datasets\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 3] Preparing train/val/test datasets...\")\n",
    "\n",
    "X_train = train_df[final_features].copy()\n",
    "X_val = val_df[final_features].copy()\n",
    "X_test = test_df[final_features].copy()\n",
    "\n",
    "y_train = train_df['grid_stress_score'].copy()\n",
    "y_val = val_df['grid_stress_score'].copy()\n",
    "y_test = test_df['grid_stress_score'].copy()\n",
    "\n",
    "print(\"  Filling missing values with 0...\")\n",
    "X_train = X_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# One-hot encode country\n",
    "if 'country' in X_train.columns:\n",
    "    print(\"  One-hot encoding country...\")\n",
    "    X_train = pd.get_dummies(X_train, columns=['country'], prefix='country', drop_first=False)\n",
    "    X_val = pd.get_dummies(X_val, columns=['country'], prefix='country', drop_first=False)\n",
    "    X_test = pd.get_dummies(X_test, columns=['country'], prefix='country', drop_first=False)\n",
    "    \n",
    "    all_columns = X_train.columns\n",
    "    X_val = X_val.reindex(columns=all_columns, fill_value=0)\n",
    "    X_test = X_test.reindex(columns=all_columns, fill_value=0)\n",
    "\n",
    "print(f\"\\n✓ Datasets prepared:\")\n",
    "print(f\"  X_train: {X_train.shape[0]:>8,} rows × {X_train.shape[1]:>3} features\")\n",
    "print(f\"  X_val:   {X_val.shape[0]:>8,} rows × {X_val.shape[1]:>3} features\")\n",
    "print(f\"  X_test:  {X_test.shape[0]:>8,} rows × {X_test.shape[1]:>3} features\")\n",
    "\n",
    "# ============================================================================\n",
    "# Final verification - ensure no leakage\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 4] Final data leakage verification...\")\n",
    "\n",
    "leakage_found = []\n",
    "\n",
    "# Check for prohibited features\n",
    "prohibited = ['net_imports', 'stress_lag', 'stress_change', 'reserve_margin_ml', \n",
    "              'forecast_load_error', 'load_rel_error']\n",
    "\n",
    "for col in X_train.columns:\n",
    "    for prob in prohibited:\n",
    "        if prob in col.lower():\n",
    "            leakage_found.append(col)\n",
    "            break\n",
    "\n",
    "if len(leakage_found) == 0:\n",
    "    print(\"  ✓ No data leakage detected\")\n",
    "    print(\"  ✓ No net_imports (used in T7/T8)\")\n",
    "    print(\"  ✓ No stress_lag (target to predict target)\")\n",
    "    print(\"  ✓ Model is production-ready\")\n",
    "else:\n",
    "    print(f\"  ❌ WARNING: Found {len(leakage_found)} suspicious features:\")\n",
    "    for feat in leakage_found:\n",
    "        print(f\"     - {feat}\")\n",
    "\n",
    "# Show feature categories\n",
    "print(f\"\\n[Step 5] Feature summary:\")\n",
    "load_feats = [f for f in X_train.columns if 'load' in f.lower() or 'Actual_Load' in f or 'Forecasted_Load' in f]\n",
    "weather_feats = [f for f in X_train.columns if any(x in f.lower() for x in ['temp', 'wind', 'solar', 'ssrd'])]\n",
    "temporal_feats = [f for f in X_train.columns if any(x in f for x in ['hour_', 'month_', 'day_of_week', 'weekend', 'peak'])]\n",
    "import_feats = [f for f in X_train.columns if 'import' in f.lower()]\n",
    "country_feats = [f for f in X_train.columns if 'country_' in f]\n",
    "generation_feats = [f for f in X_train.columns if 'Actual_Aggregated' in f]\n",
    "\n",
    "print(f\"  Load features:       {len(load_feats)}\")\n",
    "print(f\"  Weather features:    {len(weather_feats)}\")\n",
    "print(f\"  Temporal features:   {len(temporal_feats)}\")\n",
    "print(f\"  Import features:     {len(import_feats)}\")\n",
    "print(f\"  Generation features: {len(generation_feats)}\")\n",
    "print(f\"  Country indicators:  {len(country_feats)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA PREPARATION COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "941d4389-cccf-490b-ad7c-c5e77a9e0be7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 5: MODEL TRAINING - 15 ALGORITHMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define model suite\n",
    "models = {\n",
    "    # Linear models (3)\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Lasso': Lasso(alpha=0.1, max_iter=5000),\n",
    "    \n",
    "    # Tree-based (2)\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=25, min_samples_split=10, random_state=42),\n",
    "    'Decision Tree (shallow)': DecisionTreeRegressor(max_depth=15, min_samples_split=20, random_state=42),\n",
    "    \n",
    "    # Random Forest (3)\n",
    "    'Random Forest (default)': RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=20, min_samples_split=5, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest (deep)': RandomForestRegressor(\n",
    "        n_estimators=150, max_depth=30, min_samples_split=3, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest (wide)': RandomForestRegressor(\n",
    "        n_estimators=200, max_depth=15, min_samples_split=10, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    # Gradient Boosting (2)\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=100, max_depth=7, learning_rate=0.1, subsample=0.8, random_state=42\n",
    "    ),\n",
    "    'Gradient Boosting (aggressive)': GradientBoostingRegressor(\n",
    "        n_estimators=200, max_depth=5, learning_rate=0.05, subsample=0.8, random_state=42\n",
    "    ),\n",
    "    \n",
    "    # XGBoost (3)\n",
    "    'XGBoost (default)': XGBRegressor(\n",
    "        n_estimators=100, max_depth=7, learning_rate=0.1, subsample=0.8, \n",
    "        colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost (deep)': XGBRegressor(\n",
    "        n_estimators=150, max_depth=10, learning_rate=0.05, subsample=0.8,\n",
    "        colsample_bytree=0.8, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost (regularized)': XGBRegressor(\n",
    "        n_estimators=100, max_depth=7, learning_rate=0.1, subsample=0.8,\n",
    "        colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=1.0, random_state=42, n_jobs=-1\n",
    "    ),\n",
    "    \n",
    "    # LightGBM (2)\n",
    "    'LightGBM (default)': lgb.LGBMRegressor(\n",
    "        n_estimators=100, max_depth=7, learning_rate=0.1, subsample=0.8,\n",
    "        colsample_bytree=0.8, random_state=42, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "    'LightGBM (boosted)': lgb.LGBMRegressor(\n",
    "        n_estimators=200, max_depth=10, learning_rate=0.05, subsample=0.8,\n",
    "        colsample_bytree=0.8, num_leaves=128, random_state=42, n_jobs=-1, verbose=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "print(f\"\\nTraining {len(models)} models...\")\n",
    "print(f\"Features: {X_train.shape[1]} (production-ready, no leakage)\")\n",
    "print(f\"Training samples: {X_train.shape[0]:,}\\n\")\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"{'Model':<35} {'Train Time':>12} {'Val MAE':>10} {'Val RMSE':>10} {'Val R²':>10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Train_Time': train_time,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2,\n",
    "            'model_object': model\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name:<35} {train_time:>10.2f}s {mae:>10.3f} {rmse:>10.3f} {r2:>10.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name:<35} FAILED: {str(e)[:40]}\")\n",
    "\n",
    "# Find best model\n",
    "results_df = pd.DataFrame(results)\n",
    "best_idx = results_df['R2'].idxmax()\n",
    "best_model_name = results_df.loc[best_idx, 'Model']\n",
    "best_model = results_df.loc[best_idx, 'model_object']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(f\"  Validation MAE:  {results_df.loc[best_idx, 'MAE']:.3f} points\")\n",
    "print(f\"  Validation RMSE: {results_df.loc[best_idx, 'RMSE']:.3f} points\")\n",
    "print(f\"  Validation R²:   {results_df.loc[best_idx, 'R2']:.4f}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Top 5\n",
    "print(\"\\nTop 5 Models:\")\n",
    "top_5 = results_df.nlargest(5, 'R2')\n",
    "for idx, (i, row) in enumerate(top_5.iterrows(), 1):\n",
    "    print(f\"  {idx}. {row['Model']:<35} R²={row['R2']:.4f}, MAE={row['MAE']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52a6f9a4-7d4c-4a95-a8a5-7fd8a6b7d957",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 6: MODEL PERFORMANCE VISUALIZATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get predictions from best model\n",
    "print(f\"\\nGenerating predictions from: {best_model_name}\")\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 1: Model Comparison (All 15 models)\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 1] Creating model comparison plots...\")\n",
    "\n",
    "fig1 = plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plot 1: R² Comparison\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "results_sorted = results_df.sort_values('R2', ascending=True)\n",
    "colors = ['darkgreen' if x == results_df['R2'].max() else 'steelblue' for x in results_sorted['R2']]\n",
    "bars = ax1.barh(range(len(results_sorted)), results_sorted['R2'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_yticks(range(len(results_sorted)))\n",
    "ax1.set_yticklabels(results_sorted['Model'], fontsize=9)\n",
    "ax1.set_xlabel('R² Score', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('Model Comparison: R² Score', fontsize=14, fontweight='bold', pad=15)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, results_sorted['R2'])):\n",
    "    ax1.text(val + 0.01, i, f'{val:.4f}', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Plot 2: MAE Comparison\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "results_mae_sorted = results_df.sort_values('MAE', ascending=False)\n",
    "colors_mae = ['darkgreen' if x == results_df['MAE'].min() else 'coral' for x in results_mae_sorted['MAE']]\n",
    "bars2 = ax2.barh(range(len(results_mae_sorted)), results_mae_sorted['MAE'], color=colors_mae, alpha=0.7, edgecolor='black')\n",
    "ax2.set_yticks(range(len(results_mae_sorted)))\n",
    "ax2.set_yticklabels(results_mae_sorted['Model'], fontsize=9)\n",
    "ax2.set_xlabel('Mean Absolute Error (MAE)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Model Comparison: MAE', fontsize=14, fontweight='bold', pad=15)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars2, results_mae_sorted['MAE'])):\n",
    "    ax2.text(val + 0.2, i, f'{val:.2f}', va='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Plot 3: Training Time Comparison\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "results_time_sorted = results_df.sort_values('Train_Time', ascending=True)\n",
    "bars3 = ax3.barh(range(len(results_time_sorted)), results_time_sorted['Train_Time'], \n",
    "                 color='lightseagreen', alpha=0.7, edgecolor='black')\n",
    "ax3.set_yticks(range(len(results_time_sorted)))\n",
    "ax3.set_yticklabels(results_time_sorted['Model'], fontsize=9)\n",
    "ax3.set_xlabel('Training Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Model Comparison: Training Time', fontsize=14, fontweight='bold', pad=15)\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Plot 4: R² vs MAE Scatter\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "scatter = ax4.scatter(results_df['MAE'], results_df['R2'], s=200, c=results_df['Train_Time'], \n",
    "                     cmap='viridis', alpha=0.7, edgecolors='black', linewidth=1.5)\n",
    "ax4.set_xlabel('Mean Absolute Error (MAE)', fontsize=11, fontweight='bold')\n",
    "ax4.set_ylabel('R² Score', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Model Performance: R² vs MAE', fontsize=14, fontweight='bold', pad=15)\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# Add best model annotation\n",
    "best_mae = results_df.loc[best_idx, 'MAE']\n",
    "best_r2 = results_df.loc[best_idx, 'R2']\n",
    "ax4.annotate(f'Best: {best_model_name}', xy=(best_mae, best_r2), \n",
    "            xytext=(best_mae + 0.5, best_r2 - 0.05),\n",
    "            fontsize=10, fontweight='bold', color='red',\n",
    "            bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "\n",
    "plt.colorbar(scatter, ax=ax4, label='Training Time (s)')\n",
    "\n",
    "plt.suptitle('Model Performance Comparison - 15 Algorithms', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/regression_models_performance.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Model comparison plots created\")\n",
    "\n",
    "# ============================================================================\n",
    "# VISUALIZATION 2: Best Model Performance Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 2] Creating best model performance analysis...\")\n",
    "\n",
    "fig2 = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Plot 1: Actual vs Predicted (Test Set)\n",
    "ax5 = plt.subplot(2, 3, 1)\n",
    "ax5.scatter(y_test, y_test_pred, alpha=0.3, s=10, color='steelblue', edgecolors='none')\n",
    "ax5.plot([0, 75], [0, 75], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "ax5.axhline(y=50, color='orange', linestyle='--', linewidth=1.5, alpha=0.7, label='High Risk (50)')\n",
    "ax5.axvline(x=50, color='orange', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "ax5.set_xlabel('Actual Stress Score', fontsize=11, fontweight='bold')\n",
    "ax5.set_ylabel('Predicted Stress Score', fontsize=11, fontweight='bold')\n",
    "ax5.set_title(f'Actual vs Predicted - Test Set\\nR²={r2_score(y_test, y_test_pred):.4f}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# Plot 2: Residuals Distribution\n",
    "ax6 = plt.subplot(2, 3, 2)\n",
    "residuals = y_test - y_test_pred\n",
    "ax6.hist(residuals, bins=50, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "ax6.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "ax6.set_xlabel('Residuals (Actual - Predicted)', fontsize=11, fontweight='bold')\n",
    "ax6.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax6.set_title(f'Residuals Distribution\\nMean={residuals.mean():.2f}, Std={residuals.std():.2f}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 3: Residuals vs Predicted\n",
    "ax7 = plt.subplot(2, 3, 3)\n",
    "ax7.scatter(y_test_pred, residuals, alpha=0.3, s=10, color='purple', edgecolors='none')\n",
    "ax7.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax7.set_xlabel('Predicted Stress Score', fontsize=11, fontweight='bold')\n",
    "ax7.set_ylabel('Residuals', fontsize=11, fontweight='bold')\n",
    "ax7.set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "ax7.grid(alpha=0.3)\n",
    "\n",
    "# Plot 4: Error Distribution by Stress Level\n",
    "ax8 = plt.subplot(2, 3, 4)\n",
    "stress_bins = [0, 25, 50, 75]\n",
    "stress_labels = ['Normal\\n(0-24)', 'Moderate\\n(25-49)', 'High Risk\\n(50-75)']\n",
    "y_test_binned = pd.cut(y_test, bins=stress_bins, labels=stress_labels)\n",
    "abs_errors = np.abs(residuals)\n",
    "error_by_bin = pd.DataFrame({'Stress_Level': y_test_binned, 'Abs_Error': abs_errors})\n",
    "bp = error_by_bin.boxplot(column='Abs_Error', by='Stress_Level', ax=ax8, patch_artist=True)\n",
    "ax8.set_xlabel('Stress Level Category', fontsize=11, fontweight='bold')\n",
    "ax8.set_ylabel('Absolute Error', fontsize=11, fontweight='bold')\n",
    "ax8.set_title('Prediction Error by Stress Level', fontsize=12, fontweight='bold')\n",
    "plt.suptitle('')\n",
    "ax8.grid(alpha=0.3)\n",
    "\n",
    "# Plot 5: Performance Across Splits\n",
    "ax9 = plt.subplot(2, 3, 5)\n",
    "splits = ['Train', 'Validation', 'Test']\n",
    "maes = [mean_absolute_error(y_train, y_train_pred),\n",
    "        mean_absolute_error(y_val, y_val_pred),\n",
    "        mean_absolute_error(y_test, y_test_pred)]\n",
    "r2s = [r2_score(y_train, y_train_pred),\n",
    "       r2_score(y_val, y_val_pred),\n",
    "       r2_score(y_test, y_test_pred)]\n",
    "\n",
    "x = np.arange(len(splits))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax9.bar(x - width/2, maes, width, label='MAE', color='coral', alpha=0.7, edgecolor='black')\n",
    "ax9_twin = ax9.twinx()\n",
    "bars2 = ax9_twin.bar(x + width/2, r2s, width, label='R²', color='steelblue', alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax9.set_xlabel('Dataset Split', fontsize=11, fontweight='bold')\n",
    "ax9.set_ylabel('MAE', fontsize=11, fontweight='bold', color='coral')\n",
    "ax9_twin.set_ylabel('R² Score', fontsize=11, fontweight='bold', color='steelblue')\n",
    "ax9.set_title('Performance Across Splits', fontsize=12, fontweight='bold')\n",
    "ax9.set_xticks(x)\n",
    "ax9.set_xticklabels(splits)\n",
    "ax9.tick_params(axis='y', labelcolor='coral')\n",
    "ax9_twin.tick_params(axis='y', labelcolor='steelblue')\n",
    "ax9.legend(loc='upper left')\n",
    "ax9_twin.legend(loc='upper right')\n",
    "ax9.grid(alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars1, maes):\n",
    "    ax9.text(bar.get_x() + bar.get_width()/2, val + 0.2, f'{val:.2f}',\n",
    "            ha='center', fontsize=9, fontweight='bold')\n",
    "for bar, val in zip(bars2, r2s):\n",
    "    ax9_twin.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}',\n",
    "                 ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Plot 6: Prediction Distribution Comparison\n",
    "ax10 = plt.subplot(2, 3, 6)\n",
    "ax10.hist(y_test, bins=30, alpha=0.5, label='Actual', color='blue', edgecolor='black')\n",
    "ax10.hist(y_test_pred, bins=30, alpha=0.5, label='Predicted', color='red', edgecolor='black')\n",
    "ax10.axvline(x=50, color='orange', linestyle='--', linewidth=2, label='High Risk Threshold')\n",
    "ax10.set_xlabel('Stress Score', fontsize=11, fontweight='bold')\n",
    "ax10.set_ylabel('Frequency', fontsize=11, fontweight='bold')\n",
    "ax10.set_title('Distribution: Actual vs Predicted', fontsize=12, fontweight='bold')\n",
    "ax10.legend()\n",
    "ax10.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle(f'Best Model Performance Analysis: {best_model_name}', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/best_regression_model_performance.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Best model performance plots created\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUALIZATIONS COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50c0f260-3d6f-4187-991c-abae8aea5275",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tunning for best models: LightGMB and XGBoost\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model_to_tune = models[\"LightGBM (boosted)\"]\n",
    "\n",
    "param_dist = {\n",
    "    \"num_leaves\":          [31, 127, 255],     # small / medium / large tree \n",
    "    \"learning_rate\":       [0.01, 0.05, 0.1],  # slow / balanced / fast learning\n",
    "    \"min_child_samples\":   [10, 30, 100],      # leaf-level regularization\n",
    "    \"subsample\":           [0.6, 0.8, 1.0],    # row sampling (bagging)\n",
    "    \"colsample_bytree\":    [0.6, 0.8, 1.0],    # feature sampling\n",
    "    \"reg_alpha\":           [0.0, 0.1, 1.0],    # L1 regularization\n",
    "    \"reg_lambda\":          [0.0, 0.5, 1.0],    # L2 regularization\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_to_tune,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,            # try 20 random combinations\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ff86a9b-3cd2-4be0-8993-52fbe64df333",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest parameters:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "best_model_light_gmb_boosted = random_search.best_estimator_\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c065452-4a2a-497c-8507-386be55b709c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred_light_gmb_boosted = best_model_light_gmb_boosted.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "430e6177-284e-4662-adc4-8ff95cfdf189",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# see best model performance\n",
    "mae_light_gmb_boosted = mean_absolute_error(y_val, y_pred_light_gmb_boosted)\n",
    "rmse_light_gmb_boosted = np.sqrt(mean_squared_error(y_val, y_pred_light_gmb_boosted))\n",
    "r2_light_gmb_boosted = r2_score(y_val, y_pred_light_gmb_boosted)\n",
    "\n",
    "print(f\"\\nLightGBM Boosted Model Performance: MAE: {mae_light_gmb_boosted:.3f}, RMSE: {rmse_light_gmb_boosted:.3f}, R²: {r2_light_gmb_boosted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae89cea0-3722-4ac0-bbb8-72fb6466dadb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Refitting the model, since tuned hyperparameters lead to worse performance\n",
    "best_model_light_gmb_boosted.set_params(n_estimators=2000, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "193bd7f1-51ce-4934-bb29-680d4a9f304f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_model_light_gmb_boosted.fit(X_train, y_train)\n",
    "y_pred_light_gmb_boosted2 = best_model_light_gmb_boosted.predict(X_val)\n",
    "# see best model performance\n",
    "mae_light_gmb_boosted2 = mean_absolute_error(y_val, y_pred_light_gmb_boosted2)\n",
    "rmse_light_gmb_boosted2 = np.sqrt(mean_squared_error(y_val, y_pred_light_gmb_boosted2))\n",
    "r2_light_gmb_boosted2 = r2_score(y_val, y_pred_light_gmb_boosted2)\n",
    "print(f\"\\nLightGBM Boosted Model Performance: MAE: {mae_light_gmb_boosted2:.3f}, RMSE: {rmse_light_gmb_boosted2:.3f}, R²: {r2_light_gmb_boosted2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e8a589f-111e-43ca-b7e0-714b55c20d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 7: FINAL EVALUATION & BLACKOUT PREDICTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Regression Performance Summary\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 1] Regression Performance on All Splits:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\\n\")\n",
    "print(f\"{'Split':<12} {'MAE':>10} {'RMSE':>10} {'R²':>10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_train, y_train_pred),\n",
    "    ('Validation', y_val, y_pred_light_gmb_boosted2),\n",
    "    ('Test', y_test, y_test_pred)\n",
    "]:\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{split_name:<12} {mae:>10.3f} {rmse:>10.3f} {r2:>10.4f}\")\n",
    "\n",
    "# Check for overfitting\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "overfitting_gap = train_r2 - test_r2\n",
    "\n",
    "print(f\"\\nOverfitting Analysis:\")\n",
    "print(f\"  Train R²:     {train_r2:.4f}\")\n",
    "print(f\"  Test R²:      {test_r2:.4f}\")\n",
    "print(f\"  Difference:   {overfitting_gap:.4f}\")\n",
    "\n",
    "if overfitting_gap < 0.05:\n",
    "    print(f\"  Status: ✓ Excellent generalization (gap < 0.05)\")\n",
    "elif overfitting_gap < 0.10:\n",
    "    print(f\"  Status: ✓ Good generalization (gap < 0.10)\")\n",
    "else:\n",
    "    print(f\"  Status: ⚠️  Some overfitting detected (gap ≥ 0.10)\")\n",
    "\n",
    "# =======================================================================================\n",
    "# Binary Classification after getting stress score with regression - Blackout Prediction\n",
    "# =======================================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BLACKOUT PREDICTION - BINARY CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "THRESHOLD = 50\n",
    "print(f\"\\nBlackout Risk Threshold: {THRESHOLD} points\")\n",
    "print(f\"  Class 0 (Low Risk):  Stress score < {THRESHOLD}\")\n",
    "print(f\"  Class 1 (High Risk): Stress score ≥ {THRESHOLD} → BLACKOUT RISK\")\n",
    "\n",
    "# Convert to binary\n",
    "y_test_binary = (y_test >= THRESHOLD).astype(int)\n",
    "y_test_pred_binary = (y_test_pred >= THRESHOLD).astype(int)\n",
    "\n",
    "# Classification metrics\n",
    "print(\"\\n[Step 2] Classification Performance (Test Set):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "accuracy = accuracy_score(y_test_binary, y_test_pred_binary)\n",
    "precision = precision_score(y_test_binary, y_test_pred_binary, zero_division=0)\n",
    "recall = recall_score(y_test_binary, y_test_pred_binary, zero_division=0)\n",
    "f1 = f1_score(y_test_binary, y_test_pred_binary, zero_division=0)\n",
    "\n",
    "print(f\"\\n  Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"  Precision: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"  Recall:    {recall:.4f} ({recall*100:.2f}%)\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# Confusion Matrix\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 3] Confusion Matrix (Test Set):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cm = confusion_matrix(y_test_binary, y_test_pred_binary)\n",
    "\n",
    "print(f\"\\n                      Predicted\")\n",
    "print(f\"                  Low Risk  High Risk\")\n",
    "print(f\"Actual Low Risk     {cm[0,0]:>6,}     {cm[0,1]:>6,}\")\n",
    "print(f\"Actual High Risk    {cm[1,0]:>6,}     {cm[1,1]:>6,}\")\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "total = tn + fp + fn + tp\n",
    "\n",
    "print(f\"\\nDetailed Breakdown:\")\n",
    "print(f\"  True Negatives  (Correctly predicted low risk):  {tn:>6,} ({tn/total*100:>5.2f}%)\")\n",
    "print(f\"  False Positives (False alarm):                   {fp:>6,} ({fp/total*100:>5.2f}%)\")\n",
    "print(f\"  False Negatives (Missed blackout):               {fn:>6,} ({fn/total*100:>5.2f}%)\")\n",
    "print(f\"  True Positives  (Correctly predicted blackout):  {tp:>6,} ({tp/total*100:>5.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Confusion Matrix Visualization\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 4] Creating confusion matrix visualization...\")\n",
    "\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Confusion Matrix Heatmap\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True, square=True,\n",
    "            xticklabels=['Low Risk', 'High Risk'],\n",
    "            yticklabels=['Low Risk', 'High Risk'],\n",
    "            ax=ax1, annot_kws={'size': 16, 'weight': 'bold'})\n",
    "ax1.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "# Plot 2: Normalized Confusion Matrix (Percentages)\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn', cbar=True, square=True,\n",
    "            xticklabels=['Low Risk', 'High Risk'],\n",
    "            yticklabels=['Low Risk', 'High Risk'],\n",
    "            ax=ax2, annot_kws={'size': 16, 'weight': 'bold'}, vmin=0, vmax=1)\n",
    "ax2.set_xlabel('Predicted', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Actual', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Confusion Matrix - Normalized', fontsize=14, fontweight='bold', pad=15)\n",
    "\n",
    "# Plot 3: Classification Metrics Bar Chart\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "values = [accuracy, precision, recall, f1]\n",
    "colors = ['steelblue', 'green', 'orange', 'purple']\n",
    "bars = ax3.bar(metrics, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "ax3.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Classification Metrics', fontsize=14, fontweight='bold', pad=15)\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, val + 0.02, f'{val:.3f}',\n",
    "            ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Blackout Prediction - Classification Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/confussion_matrix_with_regression_blackout_prediction.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix visualization created\")\n",
    "\n",
    "# ============================================================================\n",
    "# Business Impact Analysis\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 5] Business Impact Analysis:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"\\nCritical Errors (False Negatives - Missed Blackouts):\")\n",
    "if fn > 0:\n",
    "    print(f\"  ⚠️  {fn:,} blackout events were NOT predicted\")\n",
    "    print(f\"  ⚠️  This is {fn/total*100:.2f}% of all test cases\")\n",
    "    print(f\"  ⚠️  Risk: Unprepared for {fn} potential blackouts!\")\n",
    "else:\n",
    "    print(f\"  ✓ EXCELLENT: NO missed blackouts (0 false negatives)\")\n",
    "\n",
    "print(f\"\\nFalse Alarms (False Positives):\")\n",
    "if fp > 0:\n",
    "    print(f\"  ⚠️  {fp:,} false alarms triggered\")\n",
    "    print(f\"  ⚠️  This is {fp/total*100:.2f}% of all test cases\")\n",
    "    print(f\"  ⚠️  Impact: Unnecessary emergency preparations\")\n",
    "else:\n",
    "    print(f\"  ✓ PERFECT: NO false alarms (0 false positives)\")\n",
    "\n",
    "reliability = (tn + tp) / total\n",
    "print(f\"\\n📊 Overall Prediction Reliability: {reliability:.4f} ({reliability*100:.2f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# Feature Importance\n",
    "# ============================================================================\n",
    "print(\"\\n[Step 6] Feature Importance Analysis:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Most Important Features:\")\n",
    "    print(f\"\\n{'Rank':<6} {'Feature':<50} {'Importance':>12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for idx, (i, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        print(f\"{idx:<6} {row['Feature']:<50} {row['Importance']:>12.6f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    print(\"\\n[Step 7] Creating feature importance visualization...\")\n",
    "    \n",
    "    fig2 = plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    top_20 = feature_importance.head(20).sort_values('Importance', ascending=True)\n",
    "    colors_feat = ['darkgreen' if i < 5 else 'steelblue' for i in range(len(top_20))]\n",
    "    bars = plt.barh(range(len(top_20)), top_20['Importance'], color=colors_feat, alpha=0.7, edgecolor='black')\n",
    "    plt.yticks(range(len(top_20)), top_20['Feature'], fontsize=10)\n",
    "    plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Top 20 Feature Importance - {best_model_name}', fontsize=14, fontweight='bold', pad=15)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for i, (bar, val) in enumerate(zip(bars, top_20['Importance'])):\n",
    "        plt.text(val + 0.001, i, f'{val:.4f}', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../images/feature_importance_with_regression_blackout_prediction.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Feature importance visualization created\")\n",
    "else:\n",
    "    print(\"\\n  Feature importance not available for this model type\")\n",
    "\n",
    "# ============================================================================\n",
    "# Final Summary\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nModel: {best_model_name}\")\n",
    "print(f\"Features: {X_train.shape[1]} (production-ready, no data leakage)\")\n",
    "\n",
    "print(f\"\\n📊 Regression Performance (Test Set):\")\n",
    "print(f\"  MAE:  {mean_absolute_error(y_test, y_test_pred):.3f} points (±{mean_absolute_error(y_test, y_test_pred):.1f} on 0-75 scale)\")\n",
    "print(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_test_pred)):.3f} points\")\n",
    "print(f\"  R²:   {r2_score(y_test, y_test_pred):.4f} (explains {r2_score(y_test, y_test_pred)*100:.1f}% of variance)\")\n",
    "\n",
    "print(f\"\\n🚨 Blackout Classification (Test Set):\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f} ({accuracy*100:.1f}%)\")\n",
    "print(f\"  Precision: {precision:.4f} (of predicted blackouts, {precision*100:.1f}% are real)\")\n",
    "print(f\"  Recall:    {recall:.4f} (detects {recall*100:.1f}% of actual blackouts)\")\n",
    "print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(f\"\\n✓ Data Leakage Check:\")\n",
    "print(f\"  net_imports:     Excluded (used in T7/T8 calculation)\")\n",
    "print(f\"  stress_lag_*:    Excluded (target to predict target)\")\n",
    "print(f\"  Status:          Production-ready!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EUROPEAN GRID STRESS PREDICTION - ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d453cab2-153b-4f28-b334-8bdd5b95b1d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 8: THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Threshold Optimization for Regression Model\n",
    "# ============================================================================\n",
    "print(\"\\n[PART B] Threshold optimization for regression model...\")\n",
    "print(f\"Testing different thresholds with: {best_model_name}\\n\")\n",
    "\n",
    "thresholds = [30, 35, 40, 45, 50, 55, 60]\n",
    "threshold_results = []\n",
    "\n",
    "print(f\"{'Threshold':<12} {'Accuracy':>10} {'Precision':>12} {'Recall':>10} {'F1-Score':>10} {'Missed':>10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    y_test_pred_binary = (y_test_pred >= thresh).astype(int)\n",
    "    y_test_binary_thresh = (y_test >= thresh).astype(int)\n",
    "    \n",
    "    acc = accuracy_score(y_test_binary_thresh, y_test_pred_binary)\n",
    "    prec = precision_score(y_test_binary_thresh, y_test_pred_binary, zero_division=0)\n",
    "    rec = recall_score(y_test_binary_thresh, y_test_pred_binary, zero_division=0)\n",
    "    f1 = f1_score(y_test_binary_thresh, y_test_pred_binary, zero_division=0)\n",
    "    \n",
    "    cm = confusion_matrix(y_test_binary_thresh, y_test_pred_binary)\n",
    "    fn = cm[1, 0]\n",
    "    \n",
    "    threshold_results.append({\n",
    "        'Threshold': thresh,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1,\n",
    "        'Missed': fn\n",
    "    })\n",
    "    \n",
    "    print(f\"{thresh:<12} {acc:>10.4f} {prec:>12.4f} {rec:>10.4f} {f1:>10.4f} {fn:>10,}\")\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "best_f1_idx = threshold_df['F1'].idxmax()\n",
    "best_threshold = threshold_df.loc[best_f1_idx, 'Threshold']\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(f\"BEST THRESHOLD: {best_threshold}\")\n",
    "print(f\"  F1-Score: {threshold_df.loc[best_f1_idx, 'F1']:.4f}\")\n",
    "print(f\"  Recall: {threshold_df.loc[best_f1_idx, 'Recall']:.4f}\")\n",
    "print(f\"  Missed: {threshold_df.loc[best_f1_idx, 'Missed']:,}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PART C: Compare All Approaches\n",
    "# ============================================================================\n",
    "print(\"\\n[PART C] Comparing all approaches on TEST set...\")\n",
    "\n",
    "# Get predictions on test set\n",
    "y_test_pred_reg_thresh50 = (y_test_pred >= 50).astype(int)\n",
    "y_test_pred_reg_optimized = (y_test_pred >= best_threshold).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "approaches = {\n",
    "    f'Regression (Threshold=50)': y_test_pred_reg_thresh50,\n",
    "    f'Regression (Optimized T={best_threshold})': y_test_pred_reg_optimized\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Approach':<45} {'Accuracy':>10} {'Precision':>12} {'Recall':>10} {'F1':>10}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "comparison_results = []\n",
    "for approach_name, y_pred in approaches.items():\n",
    "    acc = accuracy_score(y_test_binary, y_pred)\n",
    "    prec = precision_score(y_test_binary, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test_binary, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test_binary, y_pred, zero_division=0)\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'Approach': approach_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"{approach_name:<45} {acc:>10.4f} {prec:>12.4f} {rec:>10.4f} {f1:>10.4f}\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Find best overall approach\n",
    "best_overall_idx = comparison_df['F1'].idxmax()\n",
    "best_overall_approach = comparison_df.loc[best_overall_idx, 'Approach']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"🏆 BEST OVERALL APPROACH: {best_overall_approach}\")\n",
    "print(f\"  Test F1-Score: {comparison_df.loc[best_overall_idx, 'F1']:.4f}\")\n",
    "print(f\"  Test Recall:   {comparison_df.loc[best_overall_idx, 'Recall']:.4f}\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# ============================================================================\n",
    "# Visualizations\n",
    "# ============================================================================\n",
    "print(\"\\n[PART D] Creating comprehensive visualizations...\")\n",
    "\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Plot 2: Threshold Impact on Metrics\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "ax2.plot(threshold_df['Threshold'], threshold_df['Recall'], 'o-', linewidth=2, markersize=8, label='Recall', color='red')\n",
    "ax2.plot(threshold_df['Threshold'], threshold_df['Precision'], 's-', linewidth=2, markersize=8, label='Precision', color='blue')\n",
    "ax2.plot(threshold_df['Threshold'], threshold_df['F1'], '^-', linewidth=2, markersize=8, label='F1-Score', color='green')\n",
    "ax2.axvline(x=best_threshold, color='orange', linestyle='--', linewidth=2, label=f'Best T={best_threshold}')\n",
    "ax2.set_xlabel('Threshold', fontsize=11, fontweight='bold')\n",
    "ax2.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('Threshold Optimization', fontsize=13, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Plot 3: Approach Comparison\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "metrics_comp = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "width = 0.2\n",
    "\n",
    "for i, metric in enumerate(metrics_comp):\n",
    "    values = comparison_df[metric].values\n",
    "    ax3.bar(x_pos + i*width, values, width, label=metric, alpha=0.7, edgecolor='black')\n",
    "\n",
    "ax3.set_xlabel('Approach', fontsize=11, fontweight='bold')\n",
    "ax3.set_ylabel('Score', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('Approaches Comparison', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks(x_pos + width * 1.5)\n",
    "ax3.set_xticklabels(['Reg T=50', f'Reg T={best_threshold}'], fontsize=9, rotation=15)\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 4-6: Confusion Matrices for 3 approaches\n",
    "for idx, (approach_name, y_pred) in enumerate(approaches.items(), 3):\n",
    "    ax = plt.subplot(2, 3, idx)\n",
    "    cm = confusion_matrix(y_test_binary, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, square=True,\n",
    "                xticklabels=['Low', 'High'], yticklabels=['Low', 'High'],\n",
    "                ax=ax, annot_kws={'size': 12, 'weight': 'bold'})\n",
    "    \n",
    "    rec = recall_score(y_test_binary, y_pred)\n",
    "    f1 = f1_score(y_test_binary, y_pred)\n",
    "    \n",
    "    title = approach_name.replace('Regression', 'Reg')\n",
    "    ax.set_title(f'{title}\\nRecall={rec:.3f}, F1={f1:.3f}', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Predicted', fontsize=10, fontweight='bold')\n",
    "    ax.set_ylabel('Actual', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Complete Classification Analysis - All Approaches', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/compare_regression_and_with_threshold.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Comprehensive visualizations created\")\n",
    "\n",
    "# ============================================================================\n",
    "# Final Recommendation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FINAL RECOMMENDATION FOR PRODUCTION\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "print(f\"\\n🎯 BEST APPROACH: {best_overall_approach}\")\n",
    "print(f\"\\n📊 Test Set Performance:\")\n",
    "print(f\"  Accuracy:  {comparison_df.loc[best_overall_idx, 'Accuracy']:.4f}\")\n",
    "print(f\"  Precision: {comparison_df.loc[best_overall_idx, 'Precision']:.4f}\")\n",
    "print(f\"  Recall:    {comparison_df.loc[best_overall_idx, 'Recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {comparison_df.loc[best_overall_idx, 'F1']:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ PRODUCTION DEPLOYMENT:\")\n",
    "print(f\"  Use: {best_model_name}\")\n",
    "print(f\"  Type: Regression model with threshold = {best_threshold}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7e50aed-17eb-4264-867a-7d1aa5370a01",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REGRESSION NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n✅ Best regression model: {best_model_name}\")\n",
    "print(f\"✅ Optimal regression threshold: {best_threshold}\")\n",
    "print(f\"✅ Regression recall: {threshold_df.loc[best_f1_idx, 'Recall']:.1%}\")\n",
    "print(f\"\\nNext: Run 'grid_stress_classification_v2.ipynb' for classification optimization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Save for classification notebook\n",
    "import pickle\n",
    "import os\n",
    "# Create directory\n",
    "output_dir = \"/Workspace/Users/chavely.albert@gmail.com/regression_models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "with open(f'{output_dir}/regression_model_outputs.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'best_model': best_model,\n",
    "        'best_model_name': best_model_name,\n",
    "        'X_train': X_train,\n",
    "        'X_val': X_val,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_val': y_val,\n",
    "        'y_test': y_test,\n",
    "        'y_test_pred': y_test_pred,\n",
    "        'best_threshold': best_threshold,\n",
    "        'threshold_df': threshold_df,\n",
    "    }, f)\n",
    "\n",
    "print(\"✓ Saved: regression_model_outputs.pkl\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "grid_stress_regression",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
