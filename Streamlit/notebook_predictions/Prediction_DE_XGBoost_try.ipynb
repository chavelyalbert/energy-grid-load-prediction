{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82bf0386-39ea-4db4-ba5d-5c69f834803b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install xgboost==1.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5aeaf3d6-0691-4591-a293-40f9059f2e8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import Row\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import pickle\n",
    "import base64\n",
    "\n",
    "print(\"Imports loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8855983f-a3ae-45d9-b4b0-70d702c8fae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.table(\"workspace.default.train_set_timebins_lags\")\n",
    "\n",
    "df_de = df.filter(F.col(\"country\") == \"DE\")\n",
    "\n",
    "print(\"Total DE rows:\", df_de.count())\n",
    "display(df_de.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8b36f5f-be7d-4fe5-8cb4-08029bda1de9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "horizons = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "w = Window.partitionBy(\"country\").orderBy(\"timestamp\")\n",
    "\n",
    "for h in horizons:\n",
    "    df_de = df_de.withColumn(\n",
    "        f\"stress_plus_{h}h\",\n",
    "        F.lag(\"grid_stress_score\", -h).over(w)\n",
    "    )\n",
    "\n",
    "target_cols = [f\"stress_plus_{h}h\" for h in horizons]\n",
    "\n",
    "df_de = df_de.dropna(subset=target_cols)\n",
    "\n",
    "print(\"DE rows after targets:\", df_de.count())\n",
    "display(df_de.select(\"timestamp\", \"grid_stress_score\", *target_cols).limit(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96610f04-c7b6-4a59-b9ca-601baca20ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf = df_de.orderBy(\"timestamp\").toPandas()\n",
    "\n",
    "pdf[\"timestamp\"] = pd.to_datetime(pdf[\"timestamp\"])\n",
    "pdf = pdf.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "print(\"Pandas shape:\", pdf.shape)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b857eab-5708-4a1b-82f9-62b30c91f1f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "null_frac = pdf.isna().mean()\n",
    "high_null_cols = null_frac[null_frac > 0.5].index.tolist()\n",
    "\n",
    "pdf_clean = pdf.drop(columns=high_null_cols)\n",
    "\n",
    "# Correct indentation!\n",
    "if \"daytime_bin\" in pdf_clean.columns:\n",
    "    pdf_clean[\"daytime_bin\"] = pdf_clean[\"daytime_bin\"].map({\n",
    "        \"night\": 0,\n",
    "        \"early_morning\": 1,\n",
    "        \"morning\": 2,\n",
    "        \"afternoon\": 3,\n",
    "        \"evening\": 4\n",
    "    })\n",
    "\n",
    "exclude_cols = [\"index\", \"country\", \"timestamp\", \"grid_stress_score\"] + target_cols\n",
    "feature_cols = [c for c in pdf_clean.columns if c not in exclude_cols]\n",
    "\n",
    "print(\"Feature count:\", len(feature_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c19b23-c558-41d6-abaf-4d4beb703d86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pdf_model = pdf_clean.copy()\n",
    "\n",
    "pdf_model[feature_cols] = (\n",
    "    pdf_model[feature_cols]\n",
    "        .fillna(method=\"ffill\")\n",
    "        .fillna(method=\"bfill\")\n",
    ")\n",
    "\n",
    "for c in feature_cols:\n",
    "    if pdf_model[c].isna().any():\n",
    "        pdf_model[c] = pdf_model[c].fillna(pdf_model[c].median())\n",
    "\n",
    "print(\"Nulls remaining:\", pdf_model[feature_cols].isna().any().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae08602f-a189-445f-943c-8869ae7ce6a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "n = len(pdf_model)\n",
    "split_idx = int(n * 0.8)\n",
    "\n",
    "X = pdf_model[feature_cols].values\n",
    "y = pdf_model[target_cols]\n",
    "\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "print(\"Train size:\", X_train.shape, y_train.shape)\n",
    "print(\"Val size:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e995eb-e1e1-4d62-a6ed-dac190987c9f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "models = {}\n",
    "metrics = {}\n",
    "\n",
    "for h in horizons:\n",
    "    target_name = f\"stress_plus_{h}h\"\n",
    "    print(f\"\\n=== Training XGBoost for {target_name} ===\")\n",
    "\n",
    "    # Extract y for this horizon\n",
    "    y_tr = y_train[target_name].values\n",
    "    y_va = y_val[target_name].values\n",
    "\n",
    "    # Define model\n",
    "    model = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    model.fit(X_train, y_tr)\n",
    "\n",
    "    # Predict\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_va, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_va, y_pred))\n",
    "\n",
    "    metrics[target_name] = {\"MAE\": mae, \"RMSE\": rmse}\n",
    "    models[target_name] = model\n",
    "\n",
    "    print(f\"{target_name}: MAE={mae:.3f}, RMSE={rmse:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5631a165-4fa7-4be7-8e28-39fd8cadaceb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(\"DROP TABLE IF EXISTS workspace.default.DE_XGBoost_grid_stress_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c761994b-f8fc-4382-8241-654244592e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import base64\n",
    "from pyspark.sql import Row\n",
    "\n",
    "rows = []\n",
    "\n",
    "for h in horizons:\n",
    "    name = f\"stress_plus_{h}h\"\n",
    "    model_bytes = pickle.dumps(models[name])\n",
    "    model_b64 = base64.b64encode(model_bytes).decode(\"utf-8\")\n",
    "    \n",
    "    rows.append(Row(\n",
    "        horizon=name,\n",
    "        model_name=f\"XGBoost_{name}\",\n",
    "        model_binary=model_b64\n",
    "    ))\n",
    "\n",
    "spark_df = spark.createDataFrame(rows)\n",
    "\n",
    "spark_df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"workspace.default.DE_XGBoost_grid_stress_models\")\n",
    "\n",
    "print(\"âœ” All 6 XGBoost models saved to Delta!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ed24fda-0321-4da9-9d49-c90996bf0163",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table(\"workspace.default.DE_XGBoost_grid_stress_models\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48fe0b19-8e5e-4270-869f-d8f7b3aec52c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_check = spark.table(\"workspace.default.DE_XGBoost_grid_stress_models\")\n",
    "df_check.printSchema()\n",
    "display(df_check)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df7844b6-d8b4-46ba-aa46-8676cde22e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Horizons:\", horizons)\n",
    "print(\"Models trained:\", list(models.keys()))\n",
    "print(\"Rows created:\", len(rows))\n",
    "for r in rows:\n",
    "    print(r.horizon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dfa39500-2e8a-4472-aeda-da697451de7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_check = spark.sql(\"\"\"\n",
    "    SELECT * \n",
    "    FROM workspace.default.DE_XGBoost_grid_stress_models\n",
    "\"\"\")\n",
    "display(df_check)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Prediction_DE_XGBoost_try",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
