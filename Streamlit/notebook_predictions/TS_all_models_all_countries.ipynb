{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28c5a665-be65-4068-a452-1d85a8a1221e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install xgboost\n",
    "%pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d57dba1-6b5d-4255-9fdb-3ae062c0df7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1. Imports and Configuration\n",
    "# ============================\n",
    "import os\n",
    "import pickle\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Model types to train\n",
    "model_types = [\"xgb\", \"xgb_deep\", \"ridge\", \"mlp\", \"lgbm\"]\n",
    "\n",
    "\n",
    "# Target horizon settings\n",
    "targets = [f\"stress_plus_{h}h\" for h in range(1, 7)]\n",
    "\n",
    "# ===============\n",
    "# Save path\n",
    "country = \"ALL\"\n",
    "model_path = f\"/Workspace/workspace/streamlit/models/{country}\"\n",
    "# ===============\n",
    "\n",
    "# =========\n",
    "# after 2nd try correction, but didn't work\n",
    "# Save path (use /dbfs for Databricks file system)\n",
    "# country = \"ALL\"\n",
    "# model_path = f\"/dbfs/workspace/streamlit/models/{country}\"\n",
    "\n",
    "# ... rest of your code remains unchanged ...\n",
    "# =========\n",
    "\n",
    "# ============================\n",
    "# 2. Load Spark Tables\n",
    "# ============================\n",
    "df_train = spark.table(\"workspace.default.train_imputed_timebins_lags\")\n",
    "df_val = spark.table(\"workspace.default.validation_imputed_timebins_lags\")\n",
    "\n",
    "# ============================\n",
    "# 3. Create Target Columns (1h to 6h ahead)\n",
    "# ============================\n",
    "for h in range(1, 7):\n",
    "    df_train = df_train.withColumn(f\"stress_plus_{h}h\", F.lead(\"grid_stress_score\", h).over(Window.partitionBy(\"country\").orderBy(\"timestamp\")))\n",
    "    df_val = df_val.withColumn(f\"stress_plus_{h}h\", F.lead(\"grid_stress_score\", h).over(Window.partitionBy(\"country\").orderBy(\"timestamp\")))\n",
    "\n",
    "# ============================\n",
    "# 4. Convert to Pandas\n",
    "# ============================\n",
    "df_train_pd = df_train.toPandas()\n",
    "df_val_pd = df_val.toPandas()\n",
    "\n",
    "# ============================\n",
    "# 5. Feature Selection\n",
    "# ============================\n",
    "excluded_columns = [\n",
    "    \"index\", \"timestamp\", \"grid_stress_score\", \"country\", *targets\n",
    "]\n",
    "\n",
    "selected_features = [\n",
    "    col for col in df_train_pd.columns if col not in excluded_columns\n",
    "]\n",
    "\n",
    "# ============================\n",
    "# 6. Clean Data\n",
    "# ============================\n",
    "df_train_pd = df_train_pd.dropna(subset=selected_features + targets)\n",
    "df_val_pd = df_val_pd.dropna(subset=selected_features + targets)\n",
    "\n",
    "for col in selected_features:\n",
    "    if df_train_pd[col].dtype == \"object\":\n",
    "        df_train_pd[col] = df_train_pd[col].astype(\"category\")\n",
    "        df_val_pd[col] = df_val_pd[col].astype(\"category\")\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 7. Define Model Function\n",
    "# ============================\n",
    "def get_model(model_type):\n",
    "    if model_type == \"xgb\":\n",
    "        return XGBRegressor(n_estimators=100, random_state=42, enable_categorical=True)\n",
    "    elif model_type == \"xgb_deep\":\n",
    "        return XGBRegressor(n_estimators=300, max_depth=10, learning_rate=0.05, subsample=0.7, colsample_bytree=0.8, random_state=42, enable_categorical=True)\n",
    "    elif model_type == \"lgbm\":\n",
    "        return LGBMRegressor(n_estimators=200, learning_rate=0.05, num_leaves=31, random_state=42)\n",
    "    elif model_type == \"ridge\":\n",
    "        return Ridge(alpha=1.0)\n",
    "    elif model_type == \"mlp\":\n",
    "        return MLPRegressor(hidden_layer_sizes=(64, 64), max_iter=300, random_state=42)\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "# ============================\n",
    "# 8. Train and Save Models\n",
    "# ============================\n",
    "for model_type in model_types:\n",
    "    print(f\"\\nTraining models using: {model_type}\")\n",
    "\n",
    "    model_dir = os.path.join(model_path, model_type)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    for target in targets:\n",
    "        print(f\"Training model for target: {target}\")\n",
    "\n",
    "        # Copy feature sets\n",
    "        X_train = df_train_pd[selected_features].copy()\n",
    "        X_val = df_val_pd[selected_features].copy()\n",
    "\n",
    "        # For non-XGBoost models, encode categorical columns\n",
    "        if not model_type.startswith(\"xgb\"):\n",
    "            for col in X_train.select_dtypes(include=\"category\").columns:\n",
    "                X_train[col] = X_train[col].cat.codes\n",
    "                X_val[col] = X_val[col].cat.codes\n",
    "\n",
    "        y_train = df_train_pd[target]\n",
    "        y_val = df_val_pd[target]\n",
    "\n",
    "        model = get_model(model_type)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        with open(os.path.join(model_dir, f\"{target}.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        print(f\"{model_type} | {target} — RMSE: {rmse:.2f}, MSE: {mse:.2f}, R2: {r2:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba82b9fb-d73e-43e6-9ede-91a3a9a780c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "/home/spark-02edffbd-6028-407c-bf63-5c/.ipykernel/27287/command-7450199544602191-2068834007:78: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame.\n",
    "Try using .loc[row_indexer,col_indexer] = value instead\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  df_train_pd[col] = df_train_pd[col].astype(\"category\")\n",
    "\n",
    "Training models using: xgb\n",
    "Training model for target: stress_plus_1h\n",
    "xgb | stress_plus_1h — RMSE: 8.90, MSE: 79.17, R2: 0.71\n",
    "Training model for target: stress_plus_2h\n",
    "xgb | stress_plus_2h — RMSE: 10.87, MSE: 118.09, R2: 0.56\n",
    "Training model for target: stress_plus_3h\n",
    "xgb | stress_plus_3h — RMSE: 11.85, MSE: 140.34, R2: 0.48\n",
    "Training model for target: stress_plus_4h\n",
    "xgb | stress_plus_4h — RMSE: 12.49, MSE: 155.88, R2: 0.42\n",
    "Training model for target: stress_plus_5h\n",
    "xgb | stress_plus_5h — RMSE: 12.95, MSE: 167.61, R2: 0.38\n",
    "Training model for target: stress_plus_6h\n",
    "xgb | stress_plus_6h — RMSE: 13.21, MSE: 174.57, R2: 0.35\n",
    "\n",
    "Training models using: xgb_deep\n",
    "Training model for target: stress_plus_1h\n",
    "xgb_deep | stress_plus_1h — RMSE: 8.57, MSE: 73.38, R2: 0.73\n",
    "Training model for target: stress_plus_2h\n",
    "xgb_deep | stress_plus_2h — RMSE: 10.50, MSE: 110.17, R2: 0.59\n",
    "Training model for target: stress_plus_3h\n",
    "xgb_deep | stress_plus_3h — RMSE: 11.51, MSE: 132.43, R2: 0.51\n",
    "Training model for target: stress_plus_4h\n",
    "xgb_deep | stress_plus_4h — RMSE: 12.11, MSE: 146.54, R2: 0.45\n",
    "Training model for target: stress_plus_5h\n",
    "xgb_deep | stress_plus_5h — RMSE: 12.46, MSE: 155.16, R2: 0.42\n",
    "Training model for target: stress_plus_6h\n",
    "xgb_deep | stress_plus_6h — RMSE: 12.70, MSE: 161.20, R2: 0.40\n",
    "\n",
    "Training models using: ridge\n",
    "Training model for target: stress_plus_1h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_1h — RMSE: 24.45, MSE: 597.88, R2: -1.23\n",
    "Training model for target: stress_plus_2h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_2h — RMSE: 25.72, MSE: 661.64, R2: -1.46\n",
    "Training model for target: stress_plus_3h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_3h — RMSE: 25.56, MSE: 653.46, R2: -1.43\n",
    "Training model for target: stress_plus_4h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_4h — RMSE: 25.33, MSE: 641.76, R2: -1.39\n",
    "Training model for target: stress_plus_5h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_5h — RMSE: 24.16, MSE: 583.59, R2: -1.17\n",
    "Training model for target: stress_plus_6h\n",
    "/databricks/python/lib/python3.12/site-packages/sklearn/linear_model/_ridge.py:215: LinAlgWarning: Ill-conditioned matrix (rcond=8.66363e-19): result may not be accurate.\n",
    "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
    "ridge | stress_plus_6h — RMSE: 23.77, MSE: 564.88, R2: -1.10\n",
    "\n",
    "Training models using: mlp\n",
    "Training model for target: stress_plus_1h\n",
    "mlp | stress_plus_1h — RMSE: 15.26, MSE: 232.99, R2: 0.13\n",
    "Training model for target: stress_plus_2h\n",
    "mlp | stress_plus_2h — RMSE: 16.21, MSE: 262.69, R2: 0.02\n",
    "Training model for target: stress_plus_3h\n",
    "mlp | stress_plus_3h — RMSE: 16.38, MSE: 268.32, R2: 0.00\n",
    "Training model for target: stress_plus_4h\n",
    "mlp | stress_plus_4h — RMSE: 16.18, MSE: 261.65, R2: 0.03\n",
    "Training model for target: stress_plus_5h\n",
    "mlp | stress_plus_5h — RMSE: 16.44, MSE: 270.42, R2: -0.01\n",
    "Training model for target: stress_plus_6h\n",
    "mlp | stress_plus_6h — RMSE: 16.44, MSE: 270.17, R2: -0.01\n",
    "\n",
    "Training models using: lgbm\n",
    "Training model for target: stress_plus_1h\n",
    "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.165043 seconds.\n",
    "You can set `force_col_wise=true` to remove the overhead.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.392325\n",
    "lgbm | stress_plus_1h — RMSE: 9.04, MSE: 81.71, R2: 0.70\n",
    "Training model for target: stress_plus_2h\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076179 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.392550\n",
    "lgbm | stress_plus_2h — RMSE: 11.09, MSE: 123.02, R2: 0.54\n",
    "Training model for target: stress_plus_3h\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047312 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.393169\n",
    "lgbm | stress_plus_3h — RMSE: 12.12, MSE: 146.96, R2: 0.45\n",
    "Training model for target: stress_plus_4h\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052681 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.393619\n",
    "lgbm | stress_plus_4h — RMSE: 12.60, MSE: 158.81, R2: 0.41\n",
    "Training model for target: stress_plus_5h\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083911 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.393056\n",
    "lgbm | stress_plus_5h — RMSE: 12.90, MSE: 166.53, R2: 0.38\n",
    "Training model for target: stress_plus_6h\n",
    "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032492 seconds.\n",
    "You can set `force_row_wise=true` to remove the overhead.\n",
    "And if memory is not enough, you can set `force_col_wise=true`.\n",
    "[LightGBM] [Info] Total Bins 20859\n",
    "[LightGBM] [Info] Number of data points in the train set: 222248, number of used features: 131\n",
    "[LightGBM] [Info] Start training from score 28.392494\n",
    "lgbm | stress_plus_6h — RMSE: 13.06, MSE: 170.51, R2: 0.36"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "TS_all_models_all_countries",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
